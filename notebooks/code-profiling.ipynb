{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profile the code for writing to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kipoi\n",
    "import kipoi_veff.snv_predict as sp\n",
    "from pathlib import Path\n",
    "import os\n",
    "from kipoi.writers import HDF5BatchWriter, TsvBatchWriter, MultipleBatchWriter\n",
    "from kipoi_veff.utils.io import SyncBatchWriter\n",
    "\n",
    "model_name = \"DeepSEA/variantEffects\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'notebooks/'\n",
      "/data/nasif12/home_if12/avsec/workspace/kipoi/kipoi-veff/notebooks\n"
     ]
    }
   ],
   "source": [
    "cd notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"/tmp/kipoi\")\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install line_profiler: https://github.com/rkern/line_profiler\n",
    "# pip install line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to know where the query VCF is located and where we want to store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input vcf path\n",
    "vcf_path = \"example_data/clinvar_donor_acceptor_chr22.vcf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the dataloader arguments are set that are required to run the dataloader. Here we omit the `intervals_file` argument of the dataloader, because that has been tagged as bed file input in the `dataloader.yaml` file, which means that `score_variants` will automatically populate that argument with a temporary bed file that is generated from the VCF in order to query every variant contained in the input VCF. (\"Variant-centered approach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The datalaoder keyword arguments\n",
    "dataloader_arguments = {\"fasta_file\": \"example_data/hg19_chr22.fa\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to the vcf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /data/nasif12/home_if12/avsec/.kipoi/models/DeepSEA/variantEffects/downloaded/model_files/weights/35956ab9c28960b5a3693f470fe980c1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:03<00:00,  4.11it/s]\n"
     ]
    }
   ],
   "source": [
    "sp.score_variants(model = model_name,\n",
    "                  dl_args = dataloader_arguments,\n",
    "                  input_vcf = vcf_path,\n",
    "                  output_vcf = str(output_dir / \"output.vcf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to a tsv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is very slow (2 s / it)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /data/nasif12/home_if12/avsec/.kipoi/models/DeepSEA/variantEffects/downloaded/model_files/weights/35956ab9c28960b5a3693f470fe980c1\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi_veff.snv_predict]\u001b[0m Using variant-centered sequence generation.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:54<00:00,  3.78s/it]\n"
     ]
    }
   ],
   "source": [
    "tsv_writer =  SyncBatchWriter(TsvBatchWriter(output_dir / \"preds.tsv\"))\n",
    "sp.score_variants(model = model_name,\n",
    "                  dl_args = dataloader_arguments,\n",
    "                  input_vcf = vcf_path,\n",
    "                  output_writers=tsv_writer,\n",
    "                  output_vcf = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to an hdf5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is slow as well**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_writer = SyncBatchWriter(HDF5BatchWriter(str(output_dir / 'preds.h5')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /data/nasif12/home_if12/avsec/.kipoi/models/DeepSEA/variantEffects/downloaded/model_files/weights/35956ab9c28960b5a3693f470fe980c1\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi_veff.snv_predict]\u001b[0m Using variant-centered sequence generation.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:52<00:00,  3.57s/it]\n"
     ]
    }
   ],
   "source": [
    "sp.score_variants(model = model_name,\n",
    "                  dl_args = dataloader_arguments,\n",
    "                  input_vcf = vcf_path,\n",
    "                  output_writers=h5_writer,\n",
    "                  output_vcf = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the file after running\n",
    "!rm {h5_writer.batch_writer.file_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use line_profiler to see the bottlenecks in the code. Specify the function to benchmark with: `-f function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /data/nasif12/home_if12/avsec/.kipoi/models/DeepSEA/variantEffects/downloaded/model_files/weights/35956ab9c28960b5a3693f470fe980c1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:08<00:00,  1.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 9.0017 s\n",
       "File: /data/nasif12/home_if12/avsec/workspace/kipoi/kipoi-veff/kipoi_veff/snv_predict.py\n",
       "Function: predict_snvs at line 468\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   468                                           def predict_snvs(model,\n",
       "   469                                                            dataloader,\n",
       "   470                                                            vcf_fpath,\n",
       "   471                                                            batch_size,\n",
       "   472                                                            num_workers=0,\n",
       "   473                                                            dataloader_args=None,\n",
       "   474                                                            vcf_to_region=None,\n",
       "   475                                                            vcf_id_generator_fn=default_vcf_id_gen,\n",
       "   476                                                            evaluation_function=analyse_model_preds,\n",
       "   477                                                            evaluation_function_kwargs={'diff_types': {'logit': Logit()}},\n",
       "   478                                                            sync_pred_writer=None,\n",
       "   479                                                            use_dataloader_example_data=False,\n",
       "   480                                                            return_predictions=False,\n",
       "   481                                                            generated_seq_writer=None\n",
       "   482                                                            ):\n",
       "   483                                               \"\"\"Predict the effect of SNVs\n",
       "   484                                           \n",
       "   485                                               Prediction of effects of SNV based on a VCF. If desired the VCF can be stored with the predicted values as\n",
       "   486                                               annotation. For a detailed description of the requirements in the yaml files please take a look at\n",
       "   487                                               the core `kipoi` documentation on how to write a `dataloader.yaml` file or at the documentation of \n",
       "   488                                               `kipoi-veff` in the section: `overview/#model-and-dataloader-requirements`.\n",
       "   489                                           \n",
       "   490                                               The `evaluation_function` is evaluated after the model predictions for reference and alternative allele were\n",
       "   491                                               performed. By default the `analyse_model_preds` function is used, which executes the functions defined in its\n",
       "   492                                               argument `diff_types` on the reference and alternative prediction of every sample. When using the default\n",
       "   493                                               `analyse_model_preds`, then `evaluation_function_kwargs` has to be set to `{'diff_types': <dict>}`, where `dict`\n",
       "   494                                               is a dictionary of scoring functions (subclasses of `kipoi_veff.scores.Score`) and the keys will be used to\n",
       "   495                                               annotate the VCF (and dataframe) returned by `predict_snvs`. \n",
       "   496                                           \n",
       "   497                                               # Arguments\n",
       "   498                                                   model: A kipoi model handle generated by e.g.: `kipoi.get_model()`\n",
       "   499                                                   dataloader: Dataloader factory generated by e.g.: `kipoi.get_dataloader_factory()`\n",
       "   500                                                   vcf_fpath: Path of the VCF defining the positions that shall be assessed. Only SNVs will be tested.\n",
       "   501                                                   batch_size: Prediction batch size used for calling the data loader. Each batch will be generated in 4\n",
       "   502                                                       mutated states yielding a system RAM consumption of >= 4x batch size.\n",
       "   503                                                   num_workers: Number of parallel workers for loading the dataset.\n",
       "   504                                                   dataloader_args: arguments passed on to the dataloader for sequence generation, arguments\n",
       "   505                                                       mentioned in dataloader.yaml > postprocessing > variant_effects > bed_input will be overwritten\n",
       "   506                                                       by the methods here.\n",
       "   507                                                   vcf_to_region: Callable that generates a region compatible with dataloader/model from a cyvcf2 record\n",
       "   508                                                   vcf_id_generator_fn: Callable that generates a unique ID from a cyvcf2 record\n",
       "   509                                                   evaluation_function: effect evaluation function. Default is `analyse_model_preds`, which will get\n",
       "   510                                                       arguments defined in `evaluation_function_kwargs`\n",
       "   511                                                   evaluation_function_kwargs: kwargs passed on to `evaluation_function`.\n",
       "   512                                                   sync_pred_writer: Single writer or list of writer objects like instances of `VcfWriter`. This object\n",
       "   513                                                       will be called after effect prediction of a batch is done.\n",
       "   514                                                   use_dataloader_example_data: Fill out the missing dataloader arguments with the example values given in the\n",
       "   515                                                       dataloader.yaml.\n",
       "   516                                                   return_predictions: Return all variant effect predictions as a dictionary. Setting this to False will\n",
       "   517                                                       help maintain a low memory profile and is faster as it avoids concatenating batches after prediction.\n",
       "   518                                                   generated_seq_writer: Single writer or list of writer objects like instances of `SyncHdf5SeqWriter`.\n",
       "   519                                                       This object will be called after the DNA sequence sets have been generated. If this parameter is\n",
       "   520                                                       not None, no prediction will be performed and only DNA sequence will be written!! This is relevant\n",
       "   521                                                       if you want to use the `predict_snvs` to generate appropriate input DNA sequences for your model.\n",
       "   522                                           \n",
       "   523                                               # Returns\n",
       "   524                                                   dict: containing a pandas DataFrame containing the calculated values\n",
       "   525                                                       for each model output (target) column VCF SNV line. If `return_predictions == False`, returns None.\n",
       "   526                                               \"\"\"\n",
       "   527         1          9.0      9.0      0.0      import cyvcf2\n",
       "   528         1      15768.0  15768.0      0.2      model_info_extractor = ModelInfoExtractor(model_obj=model, dataloader_obj=dataloader)\n",
       "   529                                           \n",
       "   530                                               # If then where do I have to put my bed file in the command?\n",
       "   531                                           \n",
       "   532         1         11.0     11.0      0.0      exec_files_bed_keys = model_info_extractor.get_exec_files_bed_keys()\n",
       "   533         1          4.0      4.0      0.0      temp_bed3_file = None\n",
       "   534         1          3.0      3.0      0.0      bed3_to_vcf_idx = None\n",
       "   535                                           \n",
       "   536         1          3.0      3.0      0.0      vcf_search_regions = True\n",
       "   537                                           \n",
       "   538                                               # If there is a field for putting the a postprocessing bed file, then generate the bed file.\n",
       "   539         1          3.0      3.0      0.0      if exec_files_bed_keys is not None:\n",
       "   540         1          3.0      3.0      0.0          if vcf_to_region is not None:\n",
       "   541         1          3.0      3.0      0.0              vcf_search_regions = False\n",
       "   542                                           \n",
       "   543         1        155.0    155.0      0.0              temp_bed3_file = tempfile.mktemp()  # file path of the temp file\n",
       "   544         1         89.0     89.0      0.0              bed3_to_vcf_idx = tempfile.mktemp()\n",
       "   545                                           \n",
       "   546         1       1512.0   1512.0      0.0              vcf_fh = cyvcf2.VCF(vcf_fpath, \"r\")\n",
       "   547                                           \n",
       "   548         1          4.0      4.0      0.0              bed_line_ctr = 0\n",
       "   549         1        367.0    367.0      0.0              with gzip.open(bed3_to_vcf_idx, \"wb\") as idx_conv_fh:\n",
       "   550         1        123.0    123.0      0.0                  with BedWriter(temp_bed3_file) as ofh:\n",
       "   551       420       2426.0      5.8      0.0                      for record in vcf_fh:\n",
       "   552       419       2947.0      7.0      0.0                          if not is_indel_wrapper(record):\n",
       "   553       419       2761.0      6.6      0.0                              region = vcf_to_region(record)\n",
       "   554       419       3303.0      7.9      0.0                              id = vcf_id_generator_fn(record)\n",
       "   555       838       2537.0      3.0      0.0                              for chrom, start, end in zip(region[\"chrom\"], region[\"start\"], region[\"end\"]):\n",
       "   556       419       3730.0      8.9      0.0                                  ofh.append_interval(chrom=chrom, start=start, end=end, id=bed_line_ctr)\n",
       "   557       419       7540.0     18.0      0.1                                  idx_conv_fh.write((\"%s\\t%d\\n\" % (id, bed_line_ctr)).encode())\n",
       "   558       419       1340.0      3.2      0.0                                  bed_line_ctr += 1\n",
       "   559                                           \n",
       "   560         1          8.0      8.0      0.0              vcf_fh.close()\n",
       "   561                                               else:\n",
       "   562                                                   if vcf_to_region is not None:\n",
       "   563                                                       logger.warn(\"`vcf_to_region` will be ignored as it was set, but the dataloader does not define \"\n",
       "   564                                                                   \"a bed_input in dataloader.yaml: \"\n",
       "   565                                                                   \"postprocessing > variant_effects > bed_input.\")\n",
       "   566                                               # Assemble the paths for executing the dataloader\n",
       "   567         1          3.0      3.0      0.0      if dataloader_args is None:\n",
       "   568                                                   dataloader_args = {}\n",
       "   569                                           \n",
       "   570                                               # Copy the missing arguments from the example arguments.\n",
       "   571         1          2.0      2.0      0.0      if use_dataloader_example_data:\n",
       "   572                                                   for k in dataloader.example_kwargs:\n",
       "   573                                                       if k not in dataloader_args:\n",
       "   574                                                           dataloader_args[k] = dataloader.example_kwargs[k]\n",
       "   575                                           \n",
       "   576                                               # If there was a field for dumping the region definition bed file, then use it.\n",
       "   577         1          3.0      3.0      0.0      if (exec_files_bed_keys is not None) and (not vcf_search_regions):\n",
       "   578         2         24.0     12.0      0.0          for k in exec_files_bed_keys:\n",
       "   579         1          4.0      4.0      0.0              dataloader_args[k] = temp_bed3_file\n",
       "   580                                           \n",
       "   581         1          4.0      4.0      0.0      model_out_annotation = model_info_extractor.get_model_out_annotation()\n",
       "   582                                           \n",
       "   583         1        141.0    141.0      0.0      out_reshaper = OutputReshaper(model.schema.targets)\n",
       "   584                                           \n",
       "   585         1          2.0      2.0      0.0      res = []\n",
       "   586                                           \n",
       "   587         1      10096.0  10096.0      0.1      it = dataloader(**dataloader_args).batch_iter(batch_size=batch_size,\n",
       "   588         1        137.0    137.0      0.0                                                    num_workers=num_workers)\n",
       "   589                                           \n",
       "   590                                               # organise the writers in a list\n",
       "   591         1          3.0      3.0      0.0      if sync_pred_writer is not None:\n",
       "   592         1          5.0      5.0      0.0          if not isinstance(sync_pred_writer, list):\n",
       "   593         1          2.0      2.0      0.0              sync_pred_writer = [sync_pred_writer]\n",
       "   594                                           \n",
       "   595                                               # organise the prediction writers\n",
       "   596         1          3.0      3.0      0.0      if generated_seq_writer is not None:\n",
       "   597                                                   if not isinstance(generated_seq_writer, list):\n",
       "   598                                                       generated_seq_writer = [generated_seq_writer]\n",
       "   599                                           \n",
       "   600                                               # Open vcf again\n",
       "   601         1       1639.0   1639.0      0.0      vcf_fh = cyvcf2.VCF(vcf_fpath, \"r\")\n",
       "   602                                           \n",
       "   603         1          3.0      3.0      0.0      bed_id_conv_fh = None\n",
       "   604         1          3.0      3.0      0.0      if bed3_to_vcf_idx is not None:\n",
       "   605         1        113.0    113.0      0.0          bed_id_conv_fh = gzip.open(bed3_to_vcf_idx, \"rb\")\n",
       "   606                                           \n",
       "   607                                               # pre-process regions\n",
       "   608         1          3.0      3.0      0.0      keys = set()  # what is that?\n",
       "   609                                           \n",
       "   610         1          8.0      8.0      0.0      sample_counter = SampleCounter()\n",
       "   611                                           \n",
       "   612                                               # open the writers if possible:\n",
       "   613         1          3.0      3.0      0.0      if sync_pred_writer is not None:\n",
       "   614         1          7.0      7.0      0.0          [el.open() for el in sync_pred_writer if hasattr(el, \"open\")]\n",
       "   615                                           \n",
       "   616                                               # open seq writers if possible:\n",
       "   617         1          2.0      2.0      0.0      if generated_seq_writer is not None:\n",
       "   618                                                   [el.open() for el in generated_seq_writer if hasattr(el, \"open\")]\n",
       "   619                                           \n",
       "   620        15     612887.0  40859.1      6.8      for i, batch in enumerate(tqdm(it)):\n",
       "   621                                                   # For debugging\n",
       "   622                                                   # if i >= 10:\n",
       "   623                                                   #     break\n",
       "   624                                                   # becomes noticable for large vcf's. Is there a way to avoid it? (i.e. to exploit the iterative nature of dataloading)\n",
       "   625        14         59.0      4.2      0.0          seq_to_mut = model_info_extractor.seq_input_mutator\n",
       "   626        14         34.0      2.4      0.0          seq_to_meta = model_info_extractor.seq_input_metadata\n",
       "   627        14         50.0      3.6      0.0          eval_kwargs = _generate_seq_sets(dataloader.output_schema, batch, vcf_fh, vcf_id_generator_fn,\n",
       "   628        14         45.0      3.2      0.0                                           seq_to_mut=seq_to_mut, seq_to_meta=seq_to_meta,\n",
       "   629        14         30.0      2.1      0.0                                           sample_counter=sample_counter, vcf_search_regions=vcf_search_regions,\n",
       "   630        14         33.0      2.4      0.0                                           generate_rc=model_info_extractor.use_seq_only_rc,\n",
       "   631        14      54059.0   3861.4      0.6                                           bed_id_conv_fh=bed_id_conv_fh)\n",
       "   632        14         43.0      3.1      0.0          if eval_kwargs is None:\n",
       "   633                                                       # No generated datapoint overlapped any VCF region\n",
       "   634                                                       continue\n",
       "   635                                           \n",
       "   636        14         33.0      2.4      0.0          if generated_seq_writer is not None:\n",
       "   637                                                       for writer in generated_seq_writer:\n",
       "   638                                                           writer(eval_kwargs)\n",
       "   639                                                       # Assume that we don't actually want the predictions to be calculated...\n",
       "   640                                                       continue\n",
       "   641                                           \n",
       "   642        14         33.0      2.4      0.0          if evaluation_function_kwargs is not None:\n",
       "   643        14         42.0      3.0      0.0              assert isinstance(evaluation_function_kwargs, dict)\n",
       "   644        42        108.0      2.6      0.0              for k in evaluation_function_kwargs:\n",
       "   645        28         69.0      2.5      0.0                  eval_kwargs[k] = evaluation_function_kwargs[k]\n",
       "   646                                           \n",
       "   647        14         36.0      2.6      0.0          eval_kwargs[\"out_annotation_all_outputs\"] = model_out_annotation\n",
       "   648                                           \n",
       "   649        14     534476.0  38176.9      5.9          res_here = evaluation_function(model, output_reshaper=out_reshaper, **eval_kwargs)\n",
       "   650        98        265.0      2.7      0.0          for k in res_here:\n",
       "   651        84        223.0      2.7      0.0              keys.add(k)\n",
       "   652        84      11406.0    135.8      0.1              res_here[k].index = eval_kwargs[\"line_id\"]\n",
       "   653                                                   # write the predictions synchronously\n",
       "   654        14         33.0      2.4      0.0          if sync_pred_writer is not None:\n",
       "   655        28        105.0      3.8      0.0              for writer in sync_pred_writer:\n",
       "   656        14    7730413.0 552172.4     85.9                  writer(res_here, eval_kwargs[\"vcf_records\"], eval_kwargs[\"line_id\"])\n",
       "   657        14         33.0      2.4      0.0          if return_predictions:\n",
       "   658                                                       res.append(res_here)\n",
       "   659                                           \n",
       "   660         1         44.0     44.0      0.0      vcf_fh.close()\n",
       "   661                                           \n",
       "   662         1          3.0      3.0      0.0      if bed_id_conv_fh is not None:\n",
       "   663         1         58.0     58.0      0.0          bed_id_conv_fh.close()\n",
       "   664                                           \n",
       "   665                                               # open the writers if possible:\n",
       "   666         1          3.0      3.0      0.0      if sync_pred_writer is not None:\n",
       "   667         1         12.0     12.0      0.0          [el.close() for el in sync_pred_writer if hasattr(el, \"close\")]\n",
       "   668                                           \n",
       "   669                                               # open seq writers if possible:\n",
       "   670         1          3.0      3.0      0.0      if generated_seq_writer is not None:\n",
       "   671                                                   [el.close() for el in generated_seq_writer if hasattr(el, \"close\")]\n",
       "   672                                           \n",
       "   673         1          3.0      3.0      0.0      try:\n",
       "   674         1          3.0      3.0      0.0          if temp_bed3_file is not None:\n",
       "   675         1        194.0    194.0      0.0              os.unlink(temp_bed3_file)\n",
       "   676                                               except:\n",
       "   677                                                   pass\n",
       "   678                                           \n",
       "   679         1          4.0      4.0      0.0      if return_predictions:\n",
       "   680                                                   res_concatenated = {}\n",
       "   681                                                   for k in keys:\n",
       "   682                                                       res_concatenated[k] = pd.concat([batch[k]\n",
       "   683                                                                                        for batch in res\n",
       "   684                                                                                        if k in batch])\n",
       "   685                                                   return res_concatenated\n",
       "   686                                           \n",
       "   687         1          4.0      4.0      0.0      return None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsv_writer =  SyncBatchWriter(TsvBatchWriter(output_dir / \"preds.tsv\"))\n",
    "%lprun -f sp.predict_snvs sp.score_variants(model = model_name, dl_args=dataloader_arguments, input_vcf=vcf_path, output_writers=tsv_writer, output_vcf=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm {output_dir}/preds.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /data/nasif12/home_if12/avsec/.kipoi/models/DeepSEA/variantEffects/downloaded/model_files/weights/35956ab9c28960b5a3693f470fe980c1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00, 10.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.010126 s\n",
       "File: <ipython-input-13-eab3274b67ce>\n",
       "Function: __call__ at line 10\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    10                                               def __call__(self, predictions, records, line_ids=None):\n",
       "    11        14        374.0     26.7      3.7          validate_input(predictions, records, line_ids)\n",
       "    12                                           \n",
       "    13        14         20.0      1.4      0.2          if line_ids is None:\n",
       "    14                                                       line_ids = {}\n",
       "    15                                           \n",
       "    16        14       6524.0    466.0     64.4          batch = numpy_collate([variant_to_dict(v) for v in records])\n",
       "    17        14         93.0      6.6      0.9          batch['line_idx'] = np.array(line_ids)\n",
       "    18        14       2005.0    143.2     19.8          batch['preds'] = {k: df.values for k, df in six.iteritems(predictions)}\n",
       "    19                                           \n",
       "    20        14       1110.0     79.3     11.0          self.batch_writer.batch_write(batch)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsv_writer =  SyncBatchWriter(AsyncBatchWriter(HDF5BatchWriter(output_dir / \"preds.h5\"), max_queue_size=2))\n",
    "%lprun -f tsv_writer.__call__ sp.score_variants(model = model_name, dl_args=dataloader_arguments, input_vcf=vcf_path, output_writers=tsv_writer, output_vcf=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_to_np_dict` is the bottleneck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buffer writing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use buffer_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kipoi.writers import AsyncBatchWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kipoi_veff.utils.io import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /data/nasif12/home_if12/avsec/.kipoi/models/DeepSEA/variantEffects/downloaded/model_files/weights/35956ab9c28960b5a3693f470fe980c1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|▋         | 1/14 [00:00<00:07,  1.82it/s]\u001b[A\n",
      " 14%|█▍        | 2/14 [00:00<00:06,  1.95it/s]\u001b[A\n",
      " 21%|██▏       | 3/14 [00:01<00:05,  2.08it/s]\u001b[A\n",
      " 29%|██▊       | 4/14 [00:01<00:04,  2.09it/s]\u001b[A\n",
      " 36%|███▌      | 5/14 [00:02<00:04,  2.18it/s]\u001b[A\n",
      " 43%|████▎     | 6/14 [00:02<00:03,  2.26it/s]\u001b[A\n",
      " 50%|█████     | 7/14 [00:03<00:03,  2.31it/s]\u001b[A\n",
      " 57%|█████▋    | 8/14 [00:03<00:02,  2.35it/s]\u001b[A\n",
      " 64%|██████▍   | 9/14 [00:03<00:02,  2.28it/s]\u001b[A\n",
      " 71%|███████▏  | 10/14 [00:04<00:01,  2.29it/s]\u001b[A\n",
      " 79%|███████▊  | 11/14 [00:04<00:01,  2.30it/s]\u001b[A\n",
      " 86%|████████▌ | 12/14 [00:05<00:00,  2.34it/s]\u001b[A\n",
      " 93%|█████████▎| 13/14 [00:05<00:00,  2.38it/s]\u001b[A\n",
      "100%|██████████| 14/14 [00:05<00:00,  2.97it/s]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "tsv_writer =  SyncBatchWriter(TsvBatchWriter(output_dir / \"preds.tsv\"))\n",
    "sp.score_variants(model = model_name, dl_args=dataloader_arguments, input_vcf=vcf_path, output_writers=tsv_writer, output_vcf=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took 6 seconds in total instead of 51. Is this still the bottleneck?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /data/nasif12/home_if12/avsec/.kipoi/models/DeepSEA/variantEffects/downloaded/model_files/weights/35956ab9c28960b5a3693f470fe980c1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00, 12.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 11.2923 s\n",
       "File: /data/nasif12/home_if12/avsec/workspace/kipoi/kipoi-veff/kipoi_veff/snv_predict.py\n",
       "Function: predict_snvs at line 468\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   468                                           def predict_snvs(model,\n",
       "   469                                                            dataloader,\n",
       "   470                                                            vcf_fpath,\n",
       "   471                                                            batch_size,\n",
       "   472                                                            num_workers=0,\n",
       "   473                                                            dataloader_args=None,\n",
       "   474                                                            vcf_to_region=None,\n",
       "   475                                                            vcf_id_generator_fn=default_vcf_id_gen,\n",
       "   476                                                            evaluation_function=analyse_model_preds,\n",
       "   477                                                            evaluation_function_kwargs={'diff_types': {'logit': Logit()}},\n",
       "   478                                                            sync_pred_writer=None,\n",
       "   479                                                            use_dataloader_example_data=False,\n",
       "   480                                                            return_predictions=False,\n",
       "   481                                                            generated_seq_writer=None\n",
       "   482                                                            ):\n",
       "   483                                               \"\"\"Predict the effect of SNVs\n",
       "   484                                           \n",
       "   485                                               Prediction of effects of SNV based on a VCF. If desired the VCF can be stored with the predicted values as\n",
       "   486                                               annotation. For a detailed description of the requirements in the yaml files please take a look at\n",
       "   487                                               the core `kipoi` documentation on how to write a `dataloader.yaml` file or at the documentation of \n",
       "   488                                               `kipoi-veff` in the section: `overview/#model-and-dataloader-requirements`.\n",
       "   489                                           \n",
       "   490                                               The `evaluation_function` is evaluated after the model predictions for reference and alternative allele were\n",
       "   491                                               performed. By default the `analyse_model_preds` function is used, which executes the functions defined in its\n",
       "   492                                               argument `diff_types` on the reference and alternative prediction of every sample. When using the default\n",
       "   493                                               `analyse_model_preds`, then `evaluation_function_kwargs` has to be set to `{'diff_types': <dict>}`, where `dict`\n",
       "   494                                               is a dictionary of scoring functions (subclasses of `kipoi_veff.scores.Score`) and the keys will be used to\n",
       "   495                                               annotate the VCF (and dataframe) returned by `predict_snvs`. \n",
       "   496                                           \n",
       "   497                                               # Arguments\n",
       "   498                                                   model: A kipoi model handle generated by e.g.: `kipoi.get_model()`\n",
       "   499                                                   dataloader: Dataloader factory generated by e.g.: `kipoi.get_dataloader_factory()`\n",
       "   500                                                   vcf_fpath: Path of the VCF defining the positions that shall be assessed. Only SNVs will be tested.\n",
       "   501                                                   batch_size: Prediction batch size used for calling the data loader. Each batch will be generated in 4\n",
       "   502                                                       mutated states yielding a system RAM consumption of >= 4x batch size.\n",
       "   503                                                   num_workers: Number of parallel workers for loading the dataset.\n",
       "   504                                                   dataloader_args: arguments passed on to the dataloader for sequence generation, arguments\n",
       "   505                                                       mentioned in dataloader.yaml > postprocessing > variant_effects > bed_input will be overwritten\n",
       "   506                                                       by the methods here.\n",
       "   507                                                   vcf_to_region: Callable that generates a region compatible with dataloader/model from a cyvcf2 record\n",
       "   508                                                   vcf_id_generator_fn: Callable that generates a unique ID from a cyvcf2 record\n",
       "   509                                                   evaluation_function: effect evaluation function. Default is `analyse_model_preds`, which will get\n",
       "   510                                                       arguments defined in `evaluation_function_kwargs`\n",
       "   511                                                   evaluation_function_kwargs: kwargs passed on to `evaluation_function`.\n",
       "   512                                                   sync_pred_writer: Single writer or list of writer objects like instances of `VcfWriter`. This object\n",
       "   513                                                       will be called after effect prediction of a batch is done.\n",
       "   514                                                   use_dataloader_example_data: Fill out the missing dataloader arguments with the example values given in the\n",
       "   515                                                       dataloader.yaml.\n",
       "   516                                                   return_predictions: Return all variant effect predictions as a dictionary. Setting this to False will\n",
       "   517                                                       help maintain a low memory profile and is faster as it avoids concatenating batches after prediction.\n",
       "   518                                                   generated_seq_writer: Single writer or list of writer objects like instances of `SyncHdf5SeqWriter`.\n",
       "   519                                                       This object will be called after the DNA sequence sets have been generated. If this parameter is\n",
       "   520                                                       not None, no prediction will be performed and only DNA sequence will be written!! This is relevant\n",
       "   521                                                       if you want to use the `predict_snvs` to generate appropriate input DNA sequences for your model.\n",
       "   522                                           \n",
       "   523                                               # Returns\n",
       "   524                                                   dict: containing a pandas DataFrame containing the calculated values\n",
       "   525                                                       for each model output (target) column VCF SNV line. If `return_predictions == False`, returns None.\n",
       "   526                                               \"\"\"\n",
       "   527         1         20.0     20.0      0.0      import cyvcf2\n",
       "   528         1        570.0    570.0      0.0      model_info_extractor = ModelInfoExtractor(model_obj=model, dataloader_obj=dataloader)\n",
       "   529                                           \n",
       "   530                                               # If then where do I have to put my bed file in the command?\n",
       "   531                                           \n",
       "   532         1         19.0     19.0      0.0      exec_files_bed_keys = model_info_extractor.get_exec_files_bed_keys()\n",
       "   533         1          3.0      3.0      0.0      temp_bed3_file = None\n",
       "   534         1          3.0      3.0      0.0      bed3_to_vcf_idx = None\n",
       "   535                                           \n",
       "   536         1          3.0      3.0      0.0      vcf_search_regions = True\n",
       "   537                                           \n",
       "   538                                               # If there is a field for putting the a postprocessing bed file, then generate the bed file.\n",
       "   539         1          4.0      4.0      0.0      if exec_files_bed_keys is not None:\n",
       "   540         1          3.0      3.0      0.0          if vcf_to_region is not None:\n",
       "   541         1          3.0      3.0      0.0              vcf_search_regions = False\n",
       "   542                                           \n",
       "   543         1        152.0    152.0      0.0              temp_bed3_file = tempfile.mktemp()  # file path of the temp file\n",
       "   544         1         93.0     93.0      0.0              bed3_to_vcf_idx = tempfile.mktemp()\n",
       "   545                                           \n",
       "   546         1       1323.0   1323.0      0.0              vcf_fh = cyvcf2.VCF(vcf_fpath, \"r\")\n",
       "   547                                           \n",
       "   548         1          4.0      4.0      0.0              bed_line_ctr = 0\n",
       "   549         1        460.0    460.0      0.0              with gzip.open(bed3_to_vcf_idx, \"wb\") as idx_conv_fh:\n",
       "   550         1        133.0    133.0      0.0                  with BedWriter(temp_bed3_file) as ofh:\n",
       "   551       420       5083.0     12.1      0.0                      for record in vcf_fh:\n",
       "   552       419       3407.0      8.1      0.0                          if not is_indel_wrapper(record):\n",
       "   553       419       2858.0      6.8      0.0                              region = vcf_to_region(record)\n",
       "   554       419       3899.0      9.3      0.0                              id = vcf_id_generator_fn(record)\n",
       "   555       838       2903.0      3.5      0.0                              for chrom, start, end in zip(region[\"chrom\"], region[\"start\"], region[\"end\"]):\n",
       "   556       419       4406.0     10.5      0.0                                  ofh.append_interval(chrom=chrom, start=start, end=end, id=bed_line_ctr)\n",
       "   557       419       8719.0     20.8      0.1                                  idx_conv_fh.write((\"%s\\t%d\\n\" % (id, bed_line_ctr)).encode())\n",
       "   558       419       1239.0      3.0      0.0                                  bed_line_ctr += 1\n",
       "   559                                           \n",
       "   560         1         12.0     12.0      0.0              vcf_fh.close()\n",
       "   561                                               else:\n",
       "   562                                                   if vcf_to_region is not None:\n",
       "   563                                                       logger.warn(\"`vcf_to_region` will be ignored as it was set, but the dataloader does not define \"\n",
       "   564                                                                   \"a bed_input in dataloader.yaml: \"\n",
       "   565                                                                   \"postprocessing > variant_effects > bed_input.\")\n",
       "   566                                               # Assemble the paths for executing the dataloader\n",
       "   567         1          2.0      2.0      0.0      if dataloader_args is None:\n",
       "   568                                                   dataloader_args = {}\n",
       "   569                                           \n",
       "   570                                               # Copy the missing arguments from the example arguments.\n",
       "   571         1          3.0      3.0      0.0      if use_dataloader_example_data:\n",
       "   572                                                   for k in dataloader.example_kwargs:\n",
       "   573                                                       if k not in dataloader_args:\n",
       "   574                                                           dataloader_args[k] = dataloader.example_kwargs[k]\n",
       "   575                                           \n",
       "   576                                               # If there was a field for dumping the region definition bed file, then use it.\n",
       "   577         1          2.0      2.0      0.0      if (exec_files_bed_keys is not None) and (not vcf_search_regions):\n",
       "   578         2         19.0      9.5      0.0          for k in exec_files_bed_keys:\n",
       "   579         1          4.0      4.0      0.0              dataloader_args[k] = temp_bed3_file\n",
       "   580                                           \n",
       "   581         1          4.0      4.0      0.0      model_out_annotation = model_info_extractor.get_model_out_annotation()\n",
       "   582                                           \n",
       "   583         1        213.0    213.0      0.0      out_reshaper = OutputReshaper(model.schema.targets)\n",
       "   584                                           \n",
       "   585         1          3.0      3.0      0.0      res = []\n",
       "   586                                           \n",
       "   587         1      36832.0  36832.0      0.3      it = dataloader(**dataloader_args).batch_iter(batch_size=batch_size,\n",
       "   588         1        164.0    164.0      0.0                                                    num_workers=num_workers)\n",
       "   589                                           \n",
       "   590                                               # organise the writers in a list\n",
       "   591         1          3.0      3.0      0.0      if sync_pred_writer is not None:\n",
       "   592         1          5.0      5.0      0.0          if not isinstance(sync_pred_writer, list):\n",
       "   593         1          2.0      2.0      0.0              sync_pred_writer = [sync_pred_writer]\n",
       "   594                                           \n",
       "   595                                               # organise the prediction writers\n",
       "   596         1          2.0      2.0      0.0      if generated_seq_writer is not None:\n",
       "   597                                                   if not isinstance(generated_seq_writer, list):\n",
       "   598                                                       generated_seq_writer = [generated_seq_writer]\n",
       "   599                                           \n",
       "   600                                               # Open vcf again\n",
       "   601         1       1190.0   1190.0      0.0      vcf_fh = cyvcf2.VCF(vcf_fpath, \"r\")\n",
       "   602                                           \n",
       "   603         1          3.0      3.0      0.0      bed_id_conv_fh = None\n",
       "   604         1          2.0      2.0      0.0      if bed3_to_vcf_idx is not None:\n",
       "   605         1        125.0    125.0      0.0          bed_id_conv_fh = gzip.open(bed3_to_vcf_idx, \"rb\")\n",
       "   606                                           \n",
       "   607                                               # pre-process regions\n",
       "   608         1          3.0      3.0      0.0      keys = set()  # what is that?\n",
       "   609                                           \n",
       "   610         1         11.0     11.0      0.0      sample_counter = SampleCounter()\n",
       "   611                                           \n",
       "   612                                               # open the writers if possible:\n",
       "   613         1          2.0      2.0      0.0      if sync_pred_writer is not None:\n",
       "   614         1          7.0      7.0      0.0          [el.open() for el in sync_pred_writer if hasattr(el, \"open\")]\n",
       "   615                                           \n",
       "   616                                               # open seq writers if possible:\n",
       "   617         1          2.0      2.0      0.0      if generated_seq_writer is not None:\n",
       "   618                                                   [el.open() for el in generated_seq_writer if hasattr(el, \"open\")]\n",
       "   619                                           \n",
       "   620        15     602756.0  40183.7      5.3      for i, batch in enumerate(tqdm(it)):\n",
       "   621                                                   # For debugging\n",
       "   622                                                   # if i >= 10:\n",
       "   623                                                   #     break\n",
       "   624                                                   # becomes noticable for large vcf's. Is there a way to avoid it? (i.e. to exploit the iterative nature of dataloading)\n",
       "   625        14         49.0      3.5      0.0          seq_to_mut = model_info_extractor.seq_input_mutator\n",
       "   626        14         35.0      2.5      0.0          seq_to_meta = model_info_extractor.seq_input_metadata\n",
       "   627        14         40.0      2.9      0.0          eval_kwargs = _generate_seq_sets(dataloader.output_schema, batch, vcf_fh, vcf_id_generator_fn,\n",
       "   628        14         32.0      2.3      0.0                                           seq_to_mut=seq_to_mut, seq_to_meta=seq_to_meta,\n",
       "   629        14         32.0      2.3      0.0                                           sample_counter=sample_counter, vcf_search_regions=vcf_search_regions,\n",
       "   630        14         34.0      2.4      0.0                                           generate_rc=model_info_extractor.use_seq_only_rc,\n",
       "   631        14      51665.0   3690.4      0.5                                           bed_id_conv_fh=bed_id_conv_fh)\n",
       "   632        14         45.0      3.2      0.0          if eval_kwargs is None:\n",
       "   633                                                       # No generated datapoint overlapped any VCF region\n",
       "   634                                                       continue\n",
       "   635                                           \n",
       "   636        14         34.0      2.4      0.0          if generated_seq_writer is not None:\n",
       "   637                                                       for writer in generated_seq_writer:\n",
       "   638                                                           writer(eval_kwargs)\n",
       "   639                                                       # Assume that we don't actually want the predictions to be calculated...\n",
       "   640                                                       continue\n",
       "   641                                           \n",
       "   642        14         35.0      2.5      0.0          if evaluation_function_kwargs is not None:\n",
       "   643        14         43.0      3.1      0.0              assert isinstance(evaluation_function_kwargs, dict)\n",
       "   644        42        105.0      2.5      0.0              for k in evaluation_function_kwargs:\n",
       "   645        28         71.0      2.5      0.0                  eval_kwargs[k] = evaluation_function_kwargs[k]\n",
       "   646                                           \n",
       "   647        14         36.0      2.6      0.0          eval_kwargs[\"out_annotation_all_outputs\"] = model_out_annotation\n",
       "   648                                           \n",
       "   649        14     531238.0  37945.6      4.7          res_here = evaluation_function(model, output_reshaper=out_reshaper, **eval_kwargs)\n",
       "   650        98        280.0      2.9      0.0          for k in res_here:\n",
       "   651        84        238.0      2.8      0.0              keys.add(k)\n",
       "   652        84      11527.0    137.2      0.1              res_here[k].index = eval_kwargs[\"line_id\"]\n",
       "   653                                                   # write the predictions synchronously\n",
       "   654        14         33.0      2.4      0.0          if sync_pred_writer is not None:\n",
       "   655        28         95.0      3.4      0.0              for writer in sync_pred_writer:\n",
       "   656        14       6521.0    465.8      0.1                  writer(res_here, eval_kwargs[\"vcf_records\"], eval_kwargs[\"line_id\"])\n",
       "   657        14         30.0      2.1      0.0          if return_predictions:\n",
       "   658                                                       res.append(res_here)\n",
       "   659                                           \n",
       "   660         1         22.0     22.0      0.0      vcf_fh.close()\n",
       "   661                                           \n",
       "   662         1          2.0      2.0      0.0      if bed_id_conv_fh is not None:\n",
       "   663         1         55.0     55.0      0.0          bed_id_conv_fh.close()\n",
       "   664                                           \n",
       "   665                                               # open the writers if possible:\n",
       "   666         1          3.0      3.0      0.0      if sync_pred_writer is not None:\n",
       "   667         1   10011973.0 10011973.0     88.7          [el.close() for el in sync_pred_writer if hasattr(el, \"close\")]\n",
       "   668                                           \n",
       "   669                                               # open seq writers if possible:\n",
       "   670         1          8.0      8.0      0.0      if generated_seq_writer is not None:\n",
       "   671                                                   [el.close() for el in generated_seq_writer if hasattr(el, \"close\")]\n",
       "   672                                           \n",
       "   673         1          6.0      6.0      0.0      try:\n",
       "   674         1          7.0      7.0      0.0          if temp_bed3_file is not None:\n",
       "   675         1       1288.0   1288.0      0.0              os.unlink(temp_bed3_file)\n",
       "   676                                               except:\n",
       "   677                                                   pass\n",
       "   678                                           \n",
       "   679         1          6.0      6.0      0.0      if return_predictions:\n",
       "   680                                                   res_concatenated = {}\n",
       "   681                                                   for k in keys:\n",
       "   682                                                       res_concatenated[k] = pd.concat([batch[k]\n",
       "   683                                                                                        for batch in res\n",
       "   684                                                                                        if k in batch])\n",
       "   685                                                   return res_concatenated\n",
       "   686                                           \n",
       "   687         1          6.0      6.0      0.0      return None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsv_writer =  SyncBatchWriter(AsyncBatchWriter(HDF5BatchWriter(output_dir / \"preds.h5\"), max_queue_size=2))\n",
    "%lprun -f sp.predict_snvs sp.score_variants(model = model_name, dl_args=dataloader_arguments, input_vcf=vcf_path, output_writers=tsv_writer, output_vcf=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kipoi-cadd-py3-keras3-gpu]",
   "language": "python",
   "name": "conda-env-kipoi-cadd-py3-keras3-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
