{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Speedup the writing to disk so that model prediction takes 90% of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kipoi\n",
    "import kipoi_veff.snv_predict as sp\n",
    "from pathlib import Path\n",
    "import os\n",
    "from kipoi.writers import HDF5BatchWriter, TsvBatchWriter, MultipleBatchWriter\n",
    "from kipoi_veff.utils.io import SyncBatchWriter\n",
    "\n",
    "model_name = \"DeepSEA/variantEffects\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/avsec/workspace/kipoi/kipoi-veff/notebooks\n"
     ]
    }
   ],
   "source": [
    "cd notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"/tmp/kipoi\")\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install line_profiler: https://github.com/rkern/line_profiler\n",
    "# pip install line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to know where the query VCF is located and where we want to store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input vcf path\n",
    "vcf_path = \"example_data/clinvar_donor_acceptor_chr22.vcf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the dataloader arguments are set that are required to run the dataloader. Here we omit the `intervals_file` argument of the dataloader, because that has been tagged as bed file input in the `dataloader.yaml` file, which means that `score_variants` will automatically populate that argument with a temporary bed file that is generated from the VCF in order to query every variant contained in the input VCF. (\"Variant-centered approach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The datalaoder keyword arguments\n",
    "dataloader_arguments = {\"fasta_file\": \"example_data/hg19_chr22.fa\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to the vcf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/avsec/.kipoi/models/DeepSEA/variantEffects/downloaded/model_files/weights/35956ab9c28960b5a3693f470fe980c1\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi_veff.snv_predict]\u001b[0m Using variant-centered sequence generation.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  5.77it/s]\n"
     ]
    }
   ],
   "source": [
    "sp.score_variants(model = model_name,\n",
    "                  dl_args = dataloader_arguments,\n",
    "                  input_vcf = vcf_path,\n",
    "                  output_vcf = str(output_dir / \"output.vcf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to a tsv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is very slow (2 s / it)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/avsec/.kipoi/models/DeepSEA/variantEffects/downloaded/model_files/weights/35956ab9c28960b5a3693f470fe980c1\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi_veff.snv_predict]\u001b[0m Using variant-centered sequence generation.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:30<00:00,  2.19s/it]\n"
     ]
    }
   ],
   "source": [
    "tsv_writer =  SyncBatchWriter(TsvBatchWriter(output_dir / \"preds.tsv\"))\n",
    "sp.score_variants(model = model_name,\n",
    "                  dl_args = dataloader_arguments,\n",
    "                  input_vcf = vcf_path,\n",
    "                  output_writers=tsv_writer,\n",
    "                  output_vcf = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to an hdf5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is slow as well**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_writer = SyncBatchWriter(HDF5BatchWriter(str(output_dir / 'preds.h5')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/avsec/.kipoi/models/DeepSEA/variantEffects/downloaded/model_files/weights/35956ab9c28960b5a3693f470fe980c1\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi_veff.snv_predict]\u001b[0m Using variant-centered sequence generation.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:27<00:00,  1.95s/it]\n"
     ]
    }
   ],
   "source": [
    "sp.score_variants(model = model_name,\n",
    "                  dl_args = dataloader_arguments,\n",
    "                  input_vcf = vcf_path,\n",
    "                  output_writers=h5_writer,\n",
    "                  output_vcf = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the file after running\n",
    "!rm {h5_writer.batch_writer.file_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use line_profiler to see the bottlenecks in the code. Specify the function to benchmark with: `-f function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/avsec/.kipoi/models/DeepSEA/variantEffects/downloaded/model_files/weights/35956ab9c28960b5a3693f470fe980c1\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi_veff.snv_predict]\u001b[0m Using variant-centered sequence generation.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:50<00:00,  3.64s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 50.9212 s\n",
       "File: /home/avsec/workspace/kipoi/kipoi-veff/kipoi_veff/snv_predict.py\n",
       "Function: predict_snvs at line 468\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   468                                           def predict_snvs(model,\n",
       "   469                                                            dataloader,\n",
       "   470                                                            vcf_fpath,\n",
       "   471                                                            batch_size,\n",
       "   472                                                            num_workers=0,\n",
       "   473                                                            dataloader_args=None,\n",
       "   474                                                            vcf_to_region=None,\n",
       "   475                                                            vcf_id_generator_fn=default_vcf_id_gen,\n",
       "   476                                                            evaluation_function=analyse_model_preds,\n",
       "   477                                                            evaluation_function_kwargs={'diff_types': {'logit': Logit()}},\n",
       "   478                                                            sync_pred_writer=None,\n",
       "   479                                                            use_dataloader_example_data=False,\n",
       "   480                                                            return_predictions=False,\n",
       "   481                                                            generated_seq_writer=None\n",
       "   482                                                            ):\n",
       "   483                                               \"\"\"Predict the effect of SNVs\n",
       "   484                                           \n",
       "   485                                               Prediction of effects of SNV based on a VCF. If desired the VCF can be stored with the predicted values as\n",
       "   486                                               annotation. For a detailed description of the requirements in the yaml files please take a look at\n",
       "   487                                               the core `kipoi` documentation on how to write a `dataloader.yaml` file or at the documentation of \n",
       "   488                                               `kipoi-veff` in the section: `overview/#model-and-dataloader-requirements`.\n",
       "   489                                           \n",
       "   490                                               The `evaluation_function` is evaluated after the model predictions for reference and alternative allele were\n",
       "   491                                               performed. By default the `analyse_model_preds` function is used, which executes the functions defined in its\n",
       "   492                                               argument `diff_types` on the reference and alternative prediction of every sample. When using the default\n",
       "   493                                               `analyse_model_preds`, then `evaluation_function_kwargs` has to be set to `{'diff_types': <dict>}`, where `dict`\n",
       "   494                                               is a dictionary of scoring functions (subclasses of `kipoi_veff.scores.Score`) and the keys will be used to\n",
       "   495                                               annotate the VCF (and dataframe) returned by `predict_snvs`. \n",
       "   496                                           \n",
       "   497                                               # Arguments\n",
       "   498                                                   model: A kipoi model handle generated by e.g.: `kipoi.get_model()`\n",
       "   499                                                   dataloader: Dataloader factory generated by e.g.: `kipoi.get_dataloader_factory()`\n",
       "   500                                                   vcf_fpath: Path of the VCF defining the positions that shall be assessed. Only SNVs will be tested.\n",
       "   501                                                   batch_size: Prediction batch size used for calling the data loader. Each batch will be generated in 4\n",
       "   502                                                       mutated states yielding a system RAM consumption of >= 4x batch size.\n",
       "   503                                                   num_workers: Number of parallel workers for loading the dataset.\n",
       "   504                                                   dataloader_args: arguments passed on to the dataloader for sequence generation, arguments\n",
       "   505                                                       mentioned in dataloader.yaml > postprocessing > variant_effects > bed_input will be overwritten\n",
       "   506                                                       by the methods here.\n",
       "   507                                                   vcf_to_region: Callable that generates a region compatible with dataloader/model from a cyvcf2 record\n",
       "   508                                                   vcf_id_generator_fn: Callable that generates a unique ID from a cyvcf2 record\n",
       "   509                                                   evaluation_function: effect evaluation function. Default is `analyse_model_preds`, which will get\n",
       "   510                                                       arguments defined in `evaluation_function_kwargs`\n",
       "   511                                                   evaluation_function_kwargs: kwargs passed on to `evaluation_function`.\n",
       "   512                                                   sync_pred_writer: Single writer or list of writer objects like instances of `VcfWriter`. This object\n",
       "   513                                                       will be called after effect prediction of a batch is done.\n",
       "   514                                                   use_dataloader_example_data: Fill out the missing dataloader arguments with the example values given in the\n",
       "   515                                                       dataloader.yaml.\n",
       "   516                                                   return_predictions: Return all variant effect predictions as a dictionary. Setting this to False will\n",
       "   517                                                       help maintain a low memory profile and is faster as it avoids concatenating batches after prediction.\n",
       "   518                                                   generated_seq_writer: Single writer or list of writer objects like instances of `SyncHdf5SeqWriter`.\n",
       "   519                                                       This object will be called after the DNA sequence sets have been generated. If this parameter is\n",
       "   520                                                       not None, no prediction will be performed and only DNA sequence will be written!! This is relevant\n",
       "   521                                                       if you want to use the `predict_snvs` to generate appropriate input DNA sequences for your model.\n",
       "   522                                           \n",
       "   523                                               # Returns\n",
       "   524                                                   dict: containing a pandas DataFrame containing the calculated values\n",
       "   525                                                       for each model output (target) column VCF SNV line. If `return_predictions == False`, returns None.\n",
       "   526                                               \"\"\"\n",
       "   527         1         20.0     20.0      0.0      import cyvcf2\n",
       "   528         1        387.0    387.0      0.0      model_info_extractor = ModelInfoExtractor(model_obj=model, dataloader_obj=dataloader)\n",
       "   529                                           \n",
       "   530                                               # If then where do I have to put my bed file in the command?\n",
       "   531                                           \n",
       "   532         1          3.0      3.0      0.0      exec_files_bed_keys = model_info_extractor.get_exec_files_bed_keys()\n",
       "   533         1          2.0      2.0      0.0      temp_bed3_file = None\n",
       "   534         1          1.0      1.0      0.0      bed3_to_vcf_idx = None\n",
       "   535                                           \n",
       "   536         1          1.0      1.0      0.0      vcf_search_regions = True\n",
       "   537                                           \n",
       "   538                                               # If there is a field for putting the a postprocessing bed file, then generate the bed file.\n",
       "   539         1          2.0      2.0      0.0      if exec_files_bed_keys is not None:\n",
       "   540         1          3.0      3.0      0.0          if vcf_to_region is not None:\n",
       "   541         1          1.0      1.0      0.0              vcf_search_regions = False\n",
       "   542                                           \n",
       "   543         1        147.0    147.0      0.0              temp_bed3_file = tempfile.mktemp()  # file path of the temp file\n",
       "   544         1         85.0     85.0      0.0              bed3_to_vcf_idx = tempfile.mktemp()\n",
       "   545                                           \n",
       "   546         1        887.0    887.0      0.0              vcf_fh = cyvcf2.VCF(vcf_fpath, \"r\")\n",
       "   547                                           \n",
       "   548         1          3.0      3.0      0.0              bed_line_ctr = 0\n",
       "   549         1        189.0    189.0      0.0              with gzip.open(bed3_to_vcf_idx, \"wb\") as idx_conv_fh:\n",
       "   550         1         64.0     64.0      0.0                  with BedWriter(temp_bed3_file) as ofh:\n",
       "   551       420       1802.0      4.3      0.0                      for record in vcf_fh:\n",
       "   552       419       2609.0      6.2      0.0                          if not is_indel_wrapper(record):\n",
       "   553       419       1946.0      4.6      0.0                              region = vcf_to_region(record)\n",
       "   554       419       2684.0      6.4      0.0                              id = vcf_id_generator_fn(record)\n",
       "   555       838       2002.0      2.4      0.0                              for chrom, start, end in zip(region[\"chrom\"], region[\"start\"], region[\"end\"]):\n",
       "   556       419       3094.0      7.4      0.0                                  ofh.append_interval(chrom=chrom, start=start, end=end, id=bed_line_ctr)\n",
       "   557       419       5495.0     13.1      0.0                                  idx_conv_fh.write((\"%s\\t%d\\n\" % (id, bed_line_ctr)).encode())\n",
       "   558       419        858.0      2.0      0.0                                  bed_line_ctr += 1\n",
       "   559                                           \n",
       "   560         1         10.0     10.0      0.0              vcf_fh.close()\n",
       "   561                                               else:\n",
       "   562                                                   if vcf_to_region is not None:\n",
       "   563                                                       logger.warn(\"`vcf_to_region` will be ignored as it was set, but the dataloader does not define \"\n",
       "   564                                                                   \"a bed_input in dataloader.yaml: \"\n",
       "   565                                                                   \"postprocessing > variant_effects > bed_input.\")\n",
       "   566                                               # Assemble the paths for executing the dataloader\n",
       "   567         1          2.0      2.0      0.0      if dataloader_args is None:\n",
       "   568                                                   dataloader_args = {}\n",
       "   569                                           \n",
       "   570                                               # Copy the missing arguments from the example arguments.\n",
       "   571         1          1.0      1.0      0.0      if use_dataloader_example_data:\n",
       "   572                                                   for k in dataloader.example_kwargs:\n",
       "   573                                                       if k not in dataloader_args:\n",
       "   574                                                           dataloader_args[k] = dataloader.example_kwargs[k]\n",
       "   575                                           \n",
       "   576                                               # If there was a field for dumping the region definition bed file, then use it.\n",
       "   577         1          2.0      2.0      0.0      if (exec_files_bed_keys is not None) and (not vcf_search_regions):\n",
       "   578         2         14.0      7.0      0.0          for k in exec_files_bed_keys:\n",
       "   579         1          5.0      5.0      0.0              dataloader_args[k] = temp_bed3_file\n",
       "   580                                           \n",
       "   581         1          4.0      4.0      0.0      model_out_annotation = model_info_extractor.get_model_out_annotation()\n",
       "   582                                           \n",
       "   583         1        138.0    138.0      0.0      out_reshaper = OutputReshaper(model.schema.targets)\n",
       "   584                                           \n",
       "   585         1          2.0      2.0      0.0      res = []\n",
       "   586                                           \n",
       "   587         1       4747.0   4747.0      0.0      it = dataloader(**dataloader_args).batch_iter(batch_size=batch_size,\n",
       "   588         1         60.0     60.0      0.0                                                    num_workers=num_workers)\n",
       "   589                                           \n",
       "   590                                               # organise the writers in a list\n",
       "   591         1          2.0      2.0      0.0      if sync_pred_writer is not None:\n",
       "   592         1          3.0      3.0      0.0          if not isinstance(sync_pred_writer, list):\n",
       "   593         1          2.0      2.0      0.0              sync_pred_writer = [sync_pred_writer]\n",
       "   594                                           \n",
       "   595                                               # organise the prediction writers\n",
       "   596         1          2.0      2.0      0.0      if generated_seq_writer is not None:\n",
       "   597                                                   if not isinstance(generated_seq_writer, list):\n",
       "   598                                                       generated_seq_writer = [generated_seq_writer]\n",
       "   599                                           \n",
       "   600                                               # Open vcf again\n",
       "   601         1        450.0    450.0      0.0      vcf_fh = cyvcf2.VCF(vcf_fpath, \"r\")\n",
       "   602                                           \n",
       "   603         1          2.0      2.0      0.0      bed_id_conv_fh = None\n",
       "   604         1          2.0      2.0      0.0      if bed3_to_vcf_idx is not None:\n",
       "   605         1         70.0     70.0      0.0          bed_id_conv_fh = gzip.open(bed3_to_vcf_idx, \"rb\")\n",
       "   606                                           \n",
       "   607                                               # pre-process regions\n",
       "   608         1          2.0      2.0      0.0      keys = set()  # what is that?\n",
       "   609                                           \n",
       "   610         1          4.0      4.0      0.0      sample_counter = SampleCounter()\n",
       "   611                                           \n",
       "   612                                               # open the writers if possible:\n",
       "   613         1          2.0      2.0      0.0      if sync_pred_writer is not None:\n",
       "   614         1          8.0      8.0      0.0          [el.open() for el in sync_pred_writer if hasattr(el, \"open\")]\n",
       "   615                                           \n",
       "   616                                               # open seq writers if possible:\n",
       "   617         1          2.0      2.0      0.0      if generated_seq_writer is not None:\n",
       "   618                                                   [el.open() for el in generated_seq_writer if hasattr(el, \"open\")]\n",
       "   619                                           \n",
       "   620        15     400062.0  26670.8      0.8      for i, batch in enumerate(tqdm(it)):\n",
       "   621                                                   # For debugging\n",
       "   622                                                   # if i >= 10:\n",
       "   623                                                   #     break\n",
       "   624                                                   # becomes noticable for large vcf's. Is there a way to avoid it? (i.e. to exploit the iterative nature of dataloading)\n",
       "   625        14         48.0      3.4      0.0          seq_to_mut = model_info_extractor.seq_input_mutator\n",
       "   626        14         28.0      2.0      0.0          seq_to_meta = model_info_extractor.seq_input_metadata\n",
       "   627        14         40.0      2.9      0.0          eval_kwargs = _generate_seq_sets(dataloader.output_schema, batch, vcf_fh, vcf_id_generator_fn,\n",
       "   628        14         27.0      1.9      0.0                                           seq_to_mut=seq_to_mut, seq_to_meta=seq_to_meta,\n",
       "   629        14         28.0      2.0      0.0                                           sample_counter=sample_counter, vcf_search_regions=vcf_search_regions,\n",
       "   630        14         32.0      2.3      0.0                                           generate_rc=model_info_extractor.use_seq_only_rc,\n",
       "   631        14      40880.0   2920.0      0.1                                           bed_id_conv_fh=bed_id_conv_fh)\n",
       "   632        14         41.0      2.9      0.0          if eval_kwargs is None:\n",
       "   633                                                       # No generated datapoint overlapped any VCF region\n",
       "   634                                                       continue\n",
       "   635                                           \n",
       "   636        14         26.0      1.9      0.0          if generated_seq_writer is not None:\n",
       "   637                                                       for writer in generated_seq_writer:\n",
       "   638                                                           writer(eval_kwargs)\n",
       "   639                                                       # Assume that we don't actually want the predictions to be calculated...\n",
       "   640                                                       continue\n",
       "   641                                           \n",
       "   642        14         27.0      1.9      0.0          if evaluation_function_kwargs is not None:\n",
       "   643        14         32.0      2.3      0.0              assert isinstance(evaluation_function_kwargs, dict)\n",
       "   644        42         88.0      2.1      0.0              for k in evaluation_function_kwargs:\n",
       "   645        28         56.0      2.0      0.0                  eval_kwargs[k] = evaluation_function_kwargs[k]\n",
       "   646                                           \n",
       "   647        14         27.0      1.9      0.0          eval_kwargs[\"out_annotation_all_outputs\"] = model_out_annotation\n",
       "   648                                           \n",
       "   649        14     452821.0  32344.4      0.9          res_here = evaluation_function(model, output_reshaper=out_reshaper, **eval_kwargs)\n",
       "   650        98        271.0      2.8      0.0          for k in res_here:\n",
       "   651        84        214.0      2.5      0.0              keys.add(k)\n",
       "   652        84      10335.0    123.0      0.0              res_here[k].index = eval_kwargs[\"line_id\"]\n",
       "   653                                                   # write the predictions synchronously\n",
       "   654        14         31.0      2.2      0.0          if sync_pred_writer is not None:\n",
       "   655        28         98.0      3.5      0.0              for writer in sync_pred_writer:\n",
       "   656        14   49987966.0 3570569.0     98.2                  writer(res_here, eval_kwargs[\"vcf_records\"], eval_kwargs[\"line_id\"])\n",
       "   657        14         27.0      1.9      0.0          if return_predictions:\n",
       "   658                                                       res.append(res_here)\n",
       "   659                                           \n",
       "   660         1         15.0     15.0      0.0      vcf_fh.close()\n",
       "   661                                           \n",
       "   662         1          2.0      2.0      0.0      if bed_id_conv_fh is not None:\n",
       "   663         1         28.0     28.0      0.0          bed_id_conv_fh.close()\n",
       "   664                                           \n",
       "   665                                               # open the writers if possible:\n",
       "   666         1          2.0      2.0      0.0      if sync_pred_writer is not None:\n",
       "   667         1          9.0      9.0      0.0          [el.close() for el in sync_pred_writer if hasattr(el, \"close\")]\n",
       "   668                                           \n",
       "   669                                               # open seq writers if possible:\n",
       "   670         1          2.0      2.0      0.0      if generated_seq_writer is not None:\n",
       "   671                                                   [el.close() for el in generated_seq_writer if hasattr(el, \"close\")]\n",
       "   672                                           \n",
       "   673         1          1.0      1.0      0.0      try:\n",
       "   674         1          2.0      2.0      0.0          if temp_bed3_file is not None:\n",
       "   675         1        126.0    126.0      0.0              os.unlink(temp_bed3_file)\n",
       "   676                                               except:\n",
       "   677                                                   pass\n",
       "   678                                           \n",
       "   679         1          2.0      2.0      0.0      if return_predictions:\n",
       "   680                                                   res_concatenated = {}\n",
       "   681                                                   for k in keys:\n",
       "   682                                                       res_concatenated[k] = pd.concat([batch[k]\n",
       "   683                                                                                        for batch in res\n",
       "   684                                                                                        if k in batch])\n",
       "   685                                                   return res_concatenated\n",
       "   686                                           \n",
       "   687         1          2.0      2.0      0.0      return None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsv_writer =  SyncBatchWriter(TsvBatchWriter(output_dir / \"preds.tsv\"))\n",
    "%lprun -f sp.predict_snvs sp.score_variants(model = model_name, dl_args=dataloader_arguments, input_vcf=vcf_path, output_writers=tsv_writer, output_vcf=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that line **656** takes 98% of the time. I figured out that the following function is making it slow: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/avsec/.kipoi/models/DeepSEA/variantEffects/downloaded/model_files/weights/35956ab9c28960b5a3693f470fe980c1\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi_veff.snv_predict]\u001b[0m Using variant-centered sequence generation.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:51<00:00,  3.70s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 50.7535 s\n",
       "File: /home/avsec/workspace/kipoi/kipoi-veff/kipoi_veff/utils/io.py\n",
       "Function: __call__ at line 362\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   362                                               def __call__(self, predictions, records, line_ids=None):\n",
       "   363        14        307.0     21.9      0.0          validate_input(predictions, records, line_ids)\n",
       "   364                                           \n",
       "   365        14         16.0      1.1      0.0          if line_ids is None:\n",
       "   366                                                       line_ids = {}\n",
       "   367                                           \n",
       "   368        14       4193.0    299.5      0.0          batch = numpy_collate([variant_to_dict(v) for v in records])\n",
       "   369        14        328.0     23.4      0.0          batch['line_idx'] = np.array(line_ids)\n",
       "   370        14   44412474.0 3172319.6     87.5          batch['preds'] = {k: df_to_np_dict(df) for k, df in six.iteritems(predictions)}\n",
       "   371                                           \n",
       "   372        14    6336225.0 452587.5     12.5          self.batch_writer.batch_write(batch)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsv_writer =  SyncBatchWriter(TsvBatchWriter(output_dir / \"preds.tsv\"))\n",
    "%lprun -f tsv_writer.__call__ sp.score_variants(model = model_name, dl_args=dataloader_arguments, input_vcf=vcf_path, output_writers=tsv_writer, output_vcf=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_to_np_dict` is the bottleneck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buffer writing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use buffer_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/avsec/.kipoi/models/DeepSEA/variantEffects/downloaded/model_files/weights/35956ab9c28960b5a3693f470fe980c1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:06<00:00,  2.22it/s]\n"
     ]
    }
   ],
   "source": [
    "tsv_writer =  SyncBatchWriter(TsvBatchWriter(output_dir / \"preds.tsv\"), buffer_size=5)\n",
    "sp.score_variants(model = model_name, dl_args=dataloader_arguments, input_vcf=vcf_path, output_writers=tsv_writer, output_vcf=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took 6 seconds in total instead of 51. Is this still the bottleneck?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/avsec/.kipoi/models/DeepSEA/variantEffects/downloaded/model_files/weights/35956ab9c28960b5a3693f470fe980c1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:09<00:00,  1.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 13.4897 s\n",
       "File: /home/avsec/workspace/kipoi/kipoi-veff/kipoi_veff/snv_predict.py\n",
       "Function: predict_snvs at line 468\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   468                                           def predict_snvs(model,\n",
       "   469                                                            dataloader,\n",
       "   470                                                            vcf_fpath,\n",
       "   471                                                            batch_size,\n",
       "   472                                                            num_workers=0,\n",
       "   473                                                            dataloader_args=None,\n",
       "   474                                                            vcf_to_region=None,\n",
       "   475                                                            vcf_id_generator_fn=default_vcf_id_gen,\n",
       "   476                                                            evaluation_function=analyse_model_preds,\n",
       "   477                                                            evaluation_function_kwargs={'diff_types': {'logit': Logit()}},\n",
       "   478                                                            sync_pred_writer=None,\n",
       "   479                                                            use_dataloader_example_data=False,\n",
       "   480                                                            return_predictions=False,\n",
       "   481                                                            generated_seq_writer=None\n",
       "   482                                                            ):\n",
       "   483                                               \"\"\"Predict the effect of SNVs\n",
       "   484                                           \n",
       "   485                                               Prediction of effects of SNV based on a VCF. If desired the VCF can be stored with the predicted values as\n",
       "   486                                               annotation. For a detailed description of the requirements in the yaml files please take a look at\n",
       "   487                                               the core `kipoi` documentation on how to write a `dataloader.yaml` file or at the documentation of \n",
       "   488                                               `kipoi-veff` in the section: `overview/#model-and-dataloader-requirements`.\n",
       "   489                                           \n",
       "   490                                               The `evaluation_function` is evaluated after the model predictions for reference and alternative allele were\n",
       "   491                                               performed. By default the `analyse_model_preds` function is used, which executes the functions defined in its\n",
       "   492                                               argument `diff_types` on the reference and alternative prediction of every sample. When using the default\n",
       "   493                                               `analyse_model_preds`, then `evaluation_function_kwargs` has to be set to `{'diff_types': <dict>}`, where `dict`\n",
       "   494                                               is a dictionary of scoring functions (subclasses of `kipoi_veff.scores.Score`) and the keys will be used to\n",
       "   495                                               annotate the VCF (and dataframe) returned by `predict_snvs`. \n",
       "   496                                           \n",
       "   497                                               # Arguments\n",
       "   498                                                   model: A kipoi model handle generated by e.g.: `kipoi.get_model()`\n",
       "   499                                                   dataloader: Dataloader factory generated by e.g.: `kipoi.get_dataloader_factory()`\n",
       "   500                                                   vcf_fpath: Path of the VCF defining the positions that shall be assessed. Only SNVs will be tested.\n",
       "   501                                                   batch_size: Prediction batch size used for calling the data loader. Each batch will be generated in 4\n",
       "   502                                                       mutated states yielding a system RAM consumption of >= 4x batch size.\n",
       "   503                                                   num_workers: Number of parallel workers for loading the dataset.\n",
       "   504                                                   dataloader_args: arguments passed on to the dataloader for sequence generation, arguments\n",
       "   505                                                       mentioned in dataloader.yaml > postprocessing > variant_effects > bed_input will be overwritten\n",
       "   506                                                       by the methods here.\n",
       "   507                                                   vcf_to_region: Callable that generates a region compatible with dataloader/model from a cyvcf2 record\n",
       "   508                                                   vcf_id_generator_fn: Callable that generates a unique ID from a cyvcf2 record\n",
       "   509                                                   evaluation_function: effect evaluation function. Default is `analyse_model_preds`, which will get\n",
       "   510                                                       arguments defined in `evaluation_function_kwargs`\n",
       "   511                                                   evaluation_function_kwargs: kwargs passed on to `evaluation_function`.\n",
       "   512                                                   sync_pred_writer: Single writer or list of writer objects like instances of `VcfWriter`. This object\n",
       "   513                                                       will be called after effect prediction of a batch is done.\n",
       "   514                                                   use_dataloader_example_data: Fill out the missing dataloader arguments with the example values given in the\n",
       "   515                                                       dataloader.yaml.\n",
       "   516                                                   return_predictions: Return all variant effect predictions as a dictionary. Setting this to False will\n",
       "   517                                                       help maintain a low memory profile and is faster as it avoids concatenating batches after prediction.\n",
       "   518                                                   generated_seq_writer: Single writer or list of writer objects like instances of `SyncHdf5SeqWriter`.\n",
       "   519                                                       This object will be called after the DNA sequence sets have been generated. If this parameter is\n",
       "   520                                                       not None, no prediction will be performed and only DNA sequence will be written!! This is relevant\n",
       "   521                                                       if you want to use the `predict_snvs` to generate appropriate input DNA sequences for your model.\n",
       "   522                                           \n",
       "   523                                               # Returns\n",
       "   524                                                   dict: containing a pandas DataFrame containing the calculated values\n",
       "   525                                                       for each model output (target) column VCF SNV line. If `return_predictions == False`, returns None.\n",
       "   526                                               \"\"\"\n",
       "   527         1          6.0      6.0      0.0      import cyvcf2\n",
       "   528         1        225.0    225.0      0.0      model_info_extractor = ModelInfoExtractor(model_obj=model, dataloader_obj=dataloader)\n",
       "   529                                           \n",
       "   530                                               # If then where do I have to put my bed file in the command?\n",
       "   531                                           \n",
       "   532         1          5.0      5.0      0.0      exec_files_bed_keys = model_info_extractor.get_exec_files_bed_keys()\n",
       "   533         1          2.0      2.0      0.0      temp_bed3_file = None\n",
       "   534         1          1.0      1.0      0.0      bed3_to_vcf_idx = None\n",
       "   535                                           \n",
       "   536         1          1.0      1.0      0.0      vcf_search_regions = True\n",
       "   537                                           \n",
       "   538                                               # If there is a field for putting the a postprocessing bed file, then generate the bed file.\n",
       "   539         1          2.0      2.0      0.0      if exec_files_bed_keys is not None:\n",
       "   540         1          2.0      2.0      0.0          if vcf_to_region is not None:\n",
       "   541         1          1.0      1.0      0.0              vcf_search_regions = False\n",
       "   542                                           \n",
       "   543         1         68.0     68.0      0.0              temp_bed3_file = tempfile.mktemp()  # file path of the temp file\n",
       "   544         1         43.0     43.0      0.0              bed3_to_vcf_idx = tempfile.mktemp()\n",
       "   545                                           \n",
       "   546         1        300.0    300.0      0.0              vcf_fh = cyvcf2.VCF(vcf_fpath, \"r\")\n",
       "   547                                           \n",
       "   548         1          1.0      1.0      0.0              bed_line_ctr = 0\n",
       "   549         1        140.0    140.0      0.0              with gzip.open(bed3_to_vcf_idx, \"wb\") as idx_conv_fh:\n",
       "   550         1         43.0     43.0      0.0                  with BedWriter(temp_bed3_file) as ofh:\n",
       "   551       420       1609.0      3.8      0.0                      for record in vcf_fh:\n",
       "   552       419       2205.0      5.3      0.0                          if not is_indel_wrapper(record):\n",
       "   553       419       1704.0      4.1      0.0                              region = vcf_to_region(record)\n",
       "   554       419       2298.0      5.5      0.0                              id = vcf_id_generator_fn(record)\n",
       "   555       838       1727.0      2.1      0.0                              for chrom, start, end in zip(region[\"chrom\"], region[\"start\"], region[\"end\"]):\n",
       "   556       419       2583.0      6.2      0.0                                  ofh.append_interval(chrom=chrom, start=start, end=end, id=bed_line_ctr)\n",
       "   557       419       4701.0     11.2      0.0                                  idx_conv_fh.write((\"%s\\t%d\\n\" % (id, bed_line_ctr)).encode())\n",
       "   558       419        762.0      1.8      0.0                                  bed_line_ctr += 1\n",
       "   559                                           \n",
       "   560         1         10.0     10.0      0.0              vcf_fh.close()\n",
       "   561                                               else:\n",
       "   562                                                   if vcf_to_region is not None:\n",
       "   563                                                       logger.warn(\"`vcf_to_region` will be ignored as it was set, but the dataloader does not define \"\n",
       "   564                                                                   \"a bed_input in dataloader.yaml: \"\n",
       "   565                                                                   \"postprocessing > variant_effects > bed_input.\")\n",
       "   566                                               # Assemble the paths for executing the dataloader\n",
       "   567         1          2.0      2.0      0.0      if dataloader_args is None:\n",
       "   568                                                   dataloader_args = {}\n",
       "   569                                           \n",
       "   570                                               # Copy the missing arguments from the example arguments.\n",
       "   571         1          2.0      2.0      0.0      if use_dataloader_example_data:\n",
       "   572                                                   for k in dataloader.example_kwargs:\n",
       "   573                                                       if k not in dataloader_args:\n",
       "   574                                                           dataloader_args[k] = dataloader.example_kwargs[k]\n",
       "   575                                           \n",
       "   576                                               # If there was a field for dumping the region definition bed file, then use it.\n",
       "   577         1          2.0      2.0      0.0      if (exec_files_bed_keys is not None) and (not vcf_search_regions):\n",
       "   578         2         15.0      7.5      0.0          for k in exec_files_bed_keys:\n",
       "   579         1          3.0      3.0      0.0              dataloader_args[k] = temp_bed3_file\n",
       "   580                                           \n",
       "   581         1          3.0      3.0      0.0      model_out_annotation = model_info_extractor.get_model_out_annotation()\n",
       "   582                                           \n",
       "   583         1        139.0    139.0      0.0      out_reshaper = OutputReshaper(model.schema.targets)\n",
       "   584                                           \n",
       "   585         1          2.0      2.0      0.0      res = []\n",
       "   586                                           \n",
       "   587         1       4961.0   4961.0      0.0      it = dataloader(**dataloader_args).batch_iter(batch_size=batch_size,\n",
       "   588         1         86.0     86.0      0.0                                                    num_workers=num_workers)\n",
       "   589                                           \n",
       "   590                                               # organise the writers in a list\n",
       "   591         1          2.0      2.0      0.0      if sync_pred_writer is not None:\n",
       "   592         1          4.0      4.0      0.0          if not isinstance(sync_pred_writer, list):\n",
       "   593         1          2.0      2.0      0.0              sync_pred_writer = [sync_pred_writer]\n",
       "   594                                           \n",
       "   595                                               # organise the prediction writers\n",
       "   596         1          3.0      3.0      0.0      if generated_seq_writer is not None:\n",
       "   597                                                   if not isinstance(generated_seq_writer, list):\n",
       "   598                                                       generated_seq_writer = [generated_seq_writer]\n",
       "   599                                           \n",
       "   600                                               # Open vcf again\n",
       "   601         1        257.0    257.0      0.0      vcf_fh = cyvcf2.VCF(vcf_fpath, \"r\")\n",
       "   602                                           \n",
       "   603         1          2.0      2.0      0.0      bed_id_conv_fh = None\n",
       "   604         1          2.0      2.0      0.0      if bed3_to_vcf_idx is not None:\n",
       "   605         1         74.0     74.0      0.0          bed_id_conv_fh = gzip.open(bed3_to_vcf_idx, \"rb\")\n",
       "   606                                           \n",
       "   607                                               # pre-process regions\n",
       "   608         1          3.0      3.0      0.0      keys = set()  # what is that?\n",
       "   609                                           \n",
       "   610         1          6.0      6.0      0.0      sample_counter = SampleCounter()\n",
       "   611                                           \n",
       "   612                                               # open the writers if possible:\n",
       "   613         1          2.0      2.0      0.0      if sync_pred_writer is not None:\n",
       "   614         1          7.0      7.0      0.0          [el.open() for el in sync_pred_writer if hasattr(el, \"open\")]\n",
       "   615                                           \n",
       "   616                                               # open seq writers if possible:\n",
       "   617         1          2.0      2.0      0.0      if generated_seq_writer is not None:\n",
       "   618                                                   [el.open() for el in generated_seq_writer if hasattr(el, \"open\")]\n",
       "   619                                           \n",
       "   620        15     453747.0  30249.8      3.4      for i, batch in enumerate(tqdm(it)):\n",
       "   621                                                   # For debugging\n",
       "   622                                                   # if i >= 10:\n",
       "   623                                                   #     break\n",
       "   624                                                   # becomes noticable for large vcf's. Is there a way to avoid it? (i.e. to exploit the iterative nature of dataloading)\n",
       "   625        14         47.0      3.4      0.0          seq_to_mut = model_info_extractor.seq_input_mutator\n",
       "   626        14         51.0      3.6      0.0          seq_to_meta = model_info_extractor.seq_input_metadata\n",
       "   627        14         41.0      2.9      0.0          eval_kwargs = _generate_seq_sets(dataloader.output_schema, batch, vcf_fh, vcf_id_generator_fn,\n",
       "   628        14         23.0      1.6      0.0                                           seq_to_mut=seq_to_mut, seq_to_meta=seq_to_meta,\n",
       "   629        14         23.0      1.6      0.0                                           sample_counter=sample_counter, vcf_search_regions=vcf_search_regions,\n",
       "   630        14         27.0      1.9      0.0                                           generate_rc=model_info_extractor.use_seq_only_rc,\n",
       "   631        14      39342.0   2810.1      0.3                                           bed_id_conv_fh=bed_id_conv_fh)\n",
       "   632        14         38.0      2.7      0.0          if eval_kwargs is None:\n",
       "   633                                                       # No generated datapoint overlapped any VCF region\n",
       "   634                                                       continue\n",
       "   635                                           \n",
       "   636        14         26.0      1.9      0.0          if generated_seq_writer is not None:\n",
       "   637                                                       for writer in generated_seq_writer:\n",
       "   638                                                           writer(eval_kwargs)\n",
       "   639                                                       # Assume that we don't actually want the predictions to be calculated...\n",
       "   640                                                       continue\n",
       "   641                                           \n",
       "   642        14         24.0      1.7      0.0          if evaluation_function_kwargs is not None:\n",
       "   643        14         35.0      2.5      0.0              assert isinstance(evaluation_function_kwargs, dict)\n",
       "   644        42         83.0      2.0      0.0              for k in evaluation_function_kwargs:\n",
       "   645        28         54.0      1.9      0.0                  eval_kwargs[k] = evaluation_function_kwargs[k]\n",
       "   646                                           \n",
       "   647        14         27.0      1.9      0.0          eval_kwargs[\"out_annotation_all_outputs\"] = model_out_annotation\n",
       "   648                                           \n",
       "   649        14     409868.0  29276.3      3.0          res_here = evaluation_function(model, output_reshaper=out_reshaper, **eval_kwargs)\n",
       "   650        98        222.0      2.3      0.0          for k in res_here:\n",
       "   651        84        181.0      2.2      0.0              keys.add(k)\n",
       "   652        84       8661.0    103.1      0.1              res_here[k].index = eval_kwargs[\"line_id\"]\n",
       "   653                                                   # write the predictions synchronously\n",
       "   654        14         29.0      2.1      0.0          if sync_pred_writer is not None:\n",
       "   655        28         63.0      2.2      0.0              for writer in sync_pred_writer:\n",
       "   656        14    8514950.0 608210.7     63.1                  writer(res_here, eval_kwargs[\"vcf_records\"], eval_kwargs[\"line_id\"])\n",
       "   657        14         26.0      1.9      0.0          if return_predictions:\n",
       "   658                                                       res.append(res_here)\n",
       "   659                                           \n",
       "   660         1         13.0     13.0      0.0      vcf_fh.close()\n",
       "   661                                           \n",
       "   662         1          2.0      2.0      0.0      if bed_id_conv_fh is not None:\n",
       "   663         1         32.0     32.0      0.0          bed_id_conv_fh.close()\n",
       "   664                                           \n",
       "   665                                               # open the writers if possible:\n",
       "   666         1          2.0      2.0      0.0      if sync_pred_writer is not None:\n",
       "   667         1    4037970.0 4037970.0     29.9          [el.close() for el in sync_pred_writer if hasattr(el, \"close\")]\n",
       "   668                                           \n",
       "   669                                               # open seq writers if possible:\n",
       "   670         1          3.0      3.0      0.0      if generated_seq_writer is not None:\n",
       "   671                                                   [el.close() for el in generated_seq_writer if hasattr(el, \"close\")]\n",
       "   672                                           \n",
       "   673         1          2.0      2.0      0.0      try:\n",
       "   674         1          2.0      2.0      0.0          if temp_bed3_file is not None:\n",
       "   675         1         71.0     71.0      0.0              os.unlink(temp_bed3_file)\n",
       "   676                                               except:\n",
       "   677                                                   pass\n",
       "   678                                           \n",
       "   679         1          2.0      2.0      0.0      if return_predictions:\n",
       "   680                                                   res_concatenated = {}\n",
       "   681                                                   for k in keys:\n",
       "   682                                                       res_concatenated[k] = pd.concat([batch[k]\n",
       "   683                                                                                        for batch in res\n",
       "   684                                                                                        if k in batch])\n",
       "   685                                                   return res_concatenated\n",
       "   686                                           \n",
       "   687         1          2.0      2.0      0.0      return None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsv_writer =  SyncBatchWriter(TsvBatchWriter(output_dir / \"preds.tsv\"), buffer_size=5)\n",
    "%lprun -f sp.predict_snvs sp.score_variants(model = model_name, dl_args=dataloader_arguments, input_vcf=vcf_path, output_writers=tsv_writer, output_vcf=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. It still takes 63.1% of the time writing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking it from there\n",
    "\n",
    "- use a separate thread to write to the file on line 656\n",
    "  - question: is thread enough or do we need a separate process (using multiprocessing)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dev-kipoi-py35]",
   "language": "python",
   "name": "conda-env-dev-kipoi-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
