{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variant effect prediction\n",
    "Variant effect prediction offers a simple way to predict effects of SNVs using any model that uses DNA sequence as an input. Many different scoring methods can be chosen, but the principle relies on in-silico mutagenesis. The default input is a VCF and the default output again is a VCF annotated with predictions of variant effects. \n",
    "\n",
    "For details please take a look at the documentation in Postprocessing/Variant effect prediction. This iPython notebook goes through the basic programmatic steps that are needed to preform variant effect prediction. First a variant-centered approach will be taken and secondly overlap-based variant effect prediction will be presented. For details in how this is done programmatically, please refer to the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant centered effect prediction\n",
    "Models that accept input `.bed` files can make use of variant-centered effect prediction. This procedure starts out from the query VCF and generates genomic regions of the length of the model input, centered on the individual variant in the VCF.The model dataloader is then used to produce the model input samples for those regions, which are then mutated according to the alleles in the VCF:\n",
    "\n",
    "![img](http://kipoi.org/docs/img/notebooks/simple_var_region_generation.png)\n",
    "\n",
    "First an instance of `SnvCenteredRg` generates a temporary bed file with regions matching the input sequence length defined in the model.yaml input schema. Then the model dataloader is used to preduce the model input in batches. These chunks of data are then modified by the effect prediction algorithm, the model batch prediction function is triggered for all mutated sequence sets and finally the scoring method is applied.\n",
    "\n",
    "The selected scoring methods compare model predicitons for sequences carrying the reference or alternative allele. Those scoring methods can be `Diff` for simple subtraction of prediction, `Logit` for substraction of logit-transformed model predictions, or `DeepSEA_effect` which is a combination of `Diff` and `Logit`, which was published in the Troyanskaya et al. (2015) publication.\n",
    "\n",
    "This ipython notebook assumes that it is executed in an environment in which all dependencies for the  following models are installed: `DeepSEA/vaariantEffects`, `HAL`, `labranchor`, `MaxEntScan`, and `rbp` are installed, as well as the `--vep` flag has to be used during installing the dependencies. Now let's start out by loading the DeepSEA model and dataloader factory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kipoi\n",
    "model_name = \"DeepSEA/variantEffects\"\n",
    "# get the model\n",
    "model = kipoi.get_model(model_name)\n",
    "# get the dataloader factory\n",
    "Dataloader = kipoi.get_dataloader_factory(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will have to define the variants we want to look at, let's look at a sample VCF in chromosome 22:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##fileformat=VCFv4.0\r\n",
      "##FILTER=<ID=PASS,Description=\"All filters passed\">\r\n",
      "##contig=<ID=chr1,length=249250621>\r\n",
      "##contig=<ID=chr2,length=243199373>\r\n",
      "##contig=<ID=chr3,length=198022430>\r\n",
      "##contig=<ID=chr4,length=191154276>\r\n",
      "##contig=<ID=chr5,length=180915260>\r\n",
      "##contig=<ID=chr6,length=171115067>\r\n",
      "##contig=<ID=chr7,length=159138663>\r\n",
      "##contig=<ID=chr8,length=146364022>\r\n",
      "##contig=<ID=chr9,length=141213431>\r\n",
      "##contig=<ID=chr10,length=135534747>\r\n",
      "##contig=<ID=chr11,length=135006516>\r\n",
      "##contig=<ID=chr12,length=133851895>\r\n",
      "##contig=<ID=chr13,length=115169878>\r\n",
      "##contig=<ID=chr14,length=107349540>\r\n",
      "##contig=<ID=chr15,length=102531392>\r\n",
      "##contig=<ID=chr16,length=90354753>\r\n",
      "##contig=<ID=chr17,length=81195210>\r\n",
      "##contig=<ID=chr18,length=78077248>\r\n",
      "##contig=<ID=chr19,length=59128983>\r\n",
      "##contig=<ID=chr20,length=63025520>\r\n",
      "##contig=<ID=chr21,length=48129895>\r\n",
      "##contig=<ID=chr22,length=51304566>\r\n",
      "##contig=<ID=chrX,length=155270560>\r\n",
      "##contig=<ID=chrY,length=59373566>\r\n",
      "##contig=<ID=chrMT,length=16569>\r\n",
      "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\r\n",
      "chr22\t41320486\t4\tG\tT\t.\t.\t.\r\n",
      "chr22\t31009031\t9\tT\tG\t.\t.\t.\r\n",
      "chr22\t43024150\t15\tC\tG\t.\t.\t.\r\n",
      "chr22\t43027392\t16\tA\tG\t.\t.\t.\r\n",
      "chr22\t37469571\t122\tC\tT\t.\t.\t.\r\n",
      "chr22\t37465112\t123\tC\tG\t.\t.\t.\r\n",
      "chr22\t37494466\t124\tG\tT\t.\t.\t.\r\n",
      "chr22\t18561373\t177\tG\tT\t.\t.\t.\r\n",
      "chr22\t51065593\t241\tC\tT\t.\t.\t.\r\n",
      "chr22\t51064006\t242\tC\tT\t.\t.\t.\r\n",
      "chr22\t51065269\t243\tG\tA\t.\t.\t.\r\n",
      "chr22\t30032866\t260\tG\tT\t.\t.\t.\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 40 example_data/clinvar_donor_acceptor_chr22.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define path variable for vcf input and output paths and instantiate a VcfWriter, which will write out the annotated VCF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kipoi_veff\n",
    "from kipoi_veff import VcfWriter\n",
    "# The input vcf path\n",
    "vcf_path = \"example_data/clinvar_donor_acceptor_chr22.vcf\"\n",
    "# The output vcf path, based on the input file name    \n",
    "out_vcf_fpath = vcf_path[:-4] + \"%s.vcf\"%model_name.replace(\"/\", \"_\")\n",
    "# The writer object that will output the annotated VCF\n",
    "writer = VcfWriter(model, vcf_path, out_vcf_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to instantiate an object that can generate variant-centered regions (`SnvCenteredRg` objects). This class needs information on the model input sequence length which is extracted automatically within `ModelInfoExtractor` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information extraction from dataloader and model\n",
    "model_info = kipoi_veff.ModelInfoExtractor(model, Dataloader)\n",
    "# vcf_to_region will generate a variant-centered regions when presented a VCF record.\n",
    "vcf_to_region = kipoi_veff.SnvCenteredRg(model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the required dataloader arguments, omitting the `intervals_file` as this will be replaced by the automatically generated bed file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_arguments = {\"fasta_file\": \"example_data/hg19_chr22.fa\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the moment to run the variant effect prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:34<00:00,  2.46s/it]\n"
     ]
    }
   ],
   "source": [
    "import kipoi_veff.snv_predict as sp\n",
    "from kipoi_veff.scores import Diff, DeepSEA_effect\n",
    "sp.predict_snvs(model,\n",
    "                Dataloader,\n",
    "                vcf_path,\n",
    "                batch_size = 32,\n",
    "                dataloader_args=dataloader_arguments,\n",
    "                vcf_to_region=vcf_to_region,\n",
    "                evaluation_function_kwargs={'diff_types': {'diff': Diff(\"mean\"), 'deepsea_effect': DeepSEA_effect(\"mean\")}},\n",
    "                sync_pred_writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above we have used the variant scoring method `Diff` and `DeepSEA_effect` from `kipoi_veff` plug-in. As mentioned above variant scoring methods calculate the difference between predictions for reference and alternative, but there is another dimension to this: Models that have the `use_rc: true` flag set in their model.yaml file (DeepSEA/variantEffects does) will not only be queried with the reference and alternative carrying input sequences, but also with the reverse complement of the the sequences. In order to know of to combine predictions for forward and reverse sequences there is a initialisation flag (here set to: `\"mean\"`) for the variant scoring methods. `\"mean\"` in this case means that after calculating the effect (e.g.: Difference) the average over the difference between the prediction for the forward and for the reverse sequence should be returned. Setting `\"mean\"` complies with what was used in the Troyanskaya et al. publication.\n",
    "\n",
    "Now let's look at the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##fileformat=VCFv4.0\n",
      "##INFO=<ID=KV:kipoi:DeepSEA/variantEffects:DIFF,Number=.,Type=String,Description...\n",
      "##INFO=<ID=KV:kipoi:DeepSEA/variantEffects:DEEPSEA_EFFECT,Number=.,Type=String,D...\n",
      "##INFO=<ID=KV:kipoi:DeepSEA/variantEffects:rID,Number=.,Type=String,Description=...\n",
      "##FILTER=<ID=PASS,Description=\"All filters passed\">\n",
      "##contig=<ID=chr1,length=249250621>\n",
      "##contig=<ID=chr2,length=243199373>\n",
      "##contig=<ID=chr3,length=198022430>\n",
      "##contig=<ID=chr4,length=191154276>\n",
      "##contig=<ID=chr5,length=180915260>\n",
      "##contig=<ID=chr6,length=171115067>\n",
      "##contig=<ID=chr7,length=159138663>\n",
      "##contig=<ID=chr8,length=146364022>\n",
      "##contig=<ID=chr9,length=141213431>\n",
      "##contig=<ID=chr10,length=135534747>\n",
      "##contig=<ID=chr11,length=135006516>\n",
      "##contig=<ID=chr12,length=133851895>\n",
      "##contig=<ID=chr13,length=115169878>\n",
      "##contig=<ID=chr14,length=107349540>\n",
      "##contig=<ID=chr15,length=102531392>\n",
      "##contig=<ID=chr16,length=90354753>\n",
      "##contig=<ID=chr17,length=81195210>\n",
      "##contig=<ID=chr18,length=78077248>\n",
      "##contig=<ID=chr19,length=59128983>\n",
      "##contig=<ID=chr20,length=63025520>\n",
      "##contig=<ID=chr21,length=48129895>\n",
      "##contig=<ID=chr22,length=51304566>\n",
      "##contig=<ID=chrX,length=155270560>\n",
      "##contig=<ID=chrY,length=59373566>\n",
      "##contig=<ID=chrMT,length=16569>\n",
      "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\n",
      "chr22\t41320486\t4\tG\tT\t.\t.\tKV:kipoi:DeepSEA/variantEffects:DIFF=-0.00285008|-0.000...\n",
      "chr22\t31009031\t9\tT\tG\t.\t.\tKV:kipoi:DeepSEA/variantEffects:DIFF=-0.02733281|-0.008...\n",
      "chr22\t43024150\t15\tC\tG\t.\t.\tKV:kipoi:DeepSEA/variantEffects:DIFF=0.01077350|0.0007...\n",
      "chr22\t43027392\t16\tA\tG\t.\t.\tKV:kipoi:DeepSEA/variantEffects:DIFF=-0.12174654|-0.24...\n",
      "chr22\t37469571\t122\tC\tT\t.\t.\tKV:kipoi:DeepSEA/variantEffects:DIFF=-0.00654625|0.00...\n",
      "chr22\t37465112\t123\tC\tG\t.\t.\tKV:kipoi:DeepSEA/variantEffects:DIFF=0.00574893|0.003...\n",
      "chr22\t37494466\t124\tG\tT\t.\t.\tKV:kipoi:DeepSEA/variantEffects:DIFF=0.01308702|0.001...\n",
      "chr22\t18561373\t177\tG\tT\t.\t.\tKV:kipoi:DeepSEA/variantEffects:DIFF=-0.00669485|0.00...\n",
      "chr22\t51065593\t241\tC\tT\t.\t.\tKV:kipoi:DeepSEA/variantEffects:DIFF=0.00409312|0.001...\n",
      "chr22\t51064006\t242\tC\tT\t.\t.\tKV:kipoi:DeepSEA/variantEffects:DIFF=0.00095593|0.000...\n"
     ]
    }
   ],
   "source": [
    "# Let's print out the first 40 lines of the annotated VCF (up to 80 characters per line maximum)\n",
    "with open(\"example_data/clinvar_donor_acceptor_chr22DeepSEA_variantEffects.vcf\") as ifh:\n",
    "    for i,l in enumerate(ifh):\n",
    "        long_line = \"\"\n",
    "        if len(l)>80:\n",
    "            long_line = \"...\"\n",
    "        print(l[:80].rstrip() +long_line)\n",
    "        if i >=40:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that variants have been annotated with variant effect scores. For every different scoring method a different INFO tag was created and the score of every model output is concantenated with the `|` separator symbol. A legend is given in the header section of the VCF. The name tag indicates with model was used, wich version of it and it displays the scoring function label (`DIFF`) which is derived from the scoring function label defined in the `evaluation_function_kwargs` dictionary (`'diff'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most comprehensive representation of effect preditions is in the annotated VCF. Kipoi offers a VCF parser class that enables simple parsing of annotated VCFs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('kipoi', 'DeepSEA/variantEffects', 'DIFF'), ('kipoi', 'DeepSEA/variantEffects', 'DEEPSEA_EFFECT'), ('kipoi', 'DeepSEA/variantEffects', 'rID')]\n"
     ]
    }
   ],
   "source": [
    "from kipoi_veff.parsers import KipoiVCFParser\n",
    "vcf_reader = KipoiVCFParser(\"example_data/clinvar_donor_acceptor_chr22DeepSEA_variantEffects.vcf\")\n",
    "\n",
    "#We can have a look at the different labels which were created in the VCF\n",
    "print(list(vcf_reader.kipoi_parsed_colnames.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that two scores have been saved - `'DEEPSEA_EFFECT'` and `'DIFF'`. Additionally there is `'rID'` which is the region ID - that is the ID given by the dataloader for a genomic region which was overlapped with the variant to get the prediction that is listed in the effect score columns mentioned before. Let's take a look at the VCF entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  variant_id variant_chr  variant_pos variant_ref variant_alt  \\\n",
      "0          4       chr22     41320486           G           T   \n",
      "1          9       chr22     31009031           T           G   \n",
      "2         15       chr22     43024150           C           G   \n",
      "3         16       chr22     43027392           A           G   \n",
      "4        122       chr22     37469571           C           T   \n",
      "\n",
      "   KV_DeepSEA/variantEffects_DIFF_8988T_DNase_None_0  \\\n",
      "0                                          -0.002850   \n",
      "1                                          -0.027333   \n",
      "2                                           0.010774   \n",
      "3                                          -0.121747   \n",
      "4                                          -0.006546   \n",
      "\n",
      "   KV_DeepSEA/variantEffects_DIFF_AoSMC_DNase_None_1  \n",
      "0                                          -0.000094  \n",
      "1                                          -0.008740  \n",
      "2                                           0.000702  \n",
      "3                                          -0.247321  \n",
      "4                                           0.000784  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "entries = [el for el in vcf_reader]\n",
    "print(pd.DataFrame(entries).head().iloc[:,:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to access effect predicitons programmatically is to keep all the results in memory and receive them as a dictionary of pandas dataframes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:33<00:00,  2.41s/it]\n"
     ]
    }
   ],
   "source": [
    "effects = sp.predict_snvs(model,\n",
    "            Dataloader,\n",
    "            vcf_path,\n",
    "            batch_size = 32,\n",
    "            dataloader_args=dataloader_arguments,\n",
    "            vcf_to_region=vcf_to_region,\n",
    "            evaluation_function_kwargs={'diff_types': {'diff': Diff(\"mean\"), 'deepsea_effect': DeepSEA_effect(\"mean\")}},\n",
    "            return_predictions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every key in the `evaluation_function_kwargs` dictionary there is a key in `effects` and (the equivalent of an additional INFO tag in the VCF). Now let's take a look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff\n",
      "                        8988T_DNase_None  AoSMC_DNase_None  \\\n",
      "chr22:41320486:G:['T']         -0.002850         -0.000094   \n",
      "chr22:31009031:T:['G']         -0.027333         -0.008740   \n",
      "chr22:43024150:C:['G']          0.010773          0.000702   \n",
      "chr22:43027392:A:['G']         -0.121747         -0.247321   \n",
      "chr22:37469571:C:['T']         -0.006546          0.000784   \n",
      "\n",
      "                        Chorion_DNase_None  CLL_DNase_None  \n",
      "chr22:41320486:G:['T']           -0.001533       -0.000353  \n",
      "chr22:31009031:T:['G']           -0.003499       -0.008143  \n",
      "chr22:43024150:C:['G']            0.004689       -0.000609  \n",
      "chr22:43027392:A:['G']           -0.167689       -0.010695  \n",
      "chr22:37469571:C:['T']           -0.000383       -0.000924  \n",
      "--------------------------------------------------------------------------------\n",
      "deepsea_effect\n",
      "                        8988T_DNase_None  AoSMC_DNase_None  \\\n",
      "chr22:41320486:G:['T']          0.000377      9.663903e-07   \n",
      "chr22:31009031:T:['G']          0.004129      3.683221e-03   \n",
      "chr22:43024150:C:['G']          0.001582      1.824510e-04   \n",
      "chr22:43027392:A:['G']          0.068382      2.689577e-01   \n",
      "chr22:37469571:C:['T']          0.001174      4.173280e-04   \n",
      "\n",
      "                        Chorion_DNase_None  CLL_DNase_None  \n",
      "chr22:41320486:G:['T']            0.000162        0.000040  \n",
      "chr22:31009031:T:['G']            0.000201        0.002139  \n",
      "chr22:43024150:C:['G']            0.000322        0.000033  \n",
      "chr22:43027392:A:['G']            0.133855        0.000773  \n",
      "chr22:37469571:C:['T']            0.000008        0.000079  \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for k in effects:\n",
    "    print(k)\n",
    "    print(effects[k].head().iloc[:,:4])\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for `diff` and `deepsea_effect` there is a dataframe with variant identifiers as rows and model output labels as columns. The DeepSEA model predicts 919 tasks simultaneously hence there are 919 columns in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap based prediction\n",
    "Models that cannot predict on every region of the genome might not accept a `.bed` file as dataloader input. An example of such a model is a splicing model. Those models only work in certain regions of the genome. Here variant effect prediction can be executed based on overlaps between the regions generated by the dataloader and the variants defined in the VCF:\n",
    "\n",
    "![img](../docs/theme_dir/img/notebooks/simple_var_overlap.png)\n",
    "The procedure is similar to the variant centered effect prediction explained above, but in this case no temporary bed file is generated and the effect prediction is based on all the regions generated by the dataloader which overlap any variant in the VCF. If a region is overlapped by two variants the effect of the two variants is predicted independently.\n",
    "\n",
    "Here the VCF has to be tabixed so that a regional lookup can be performed efficiently, this can be done by using the `ensure_tabixed` function, the rest remains the same as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kipoi\n",
    "from kipoi_veff import VcfWriter\n",
    "from kipoi_veff import ensure_tabixed_vcf\n",
    "# Use a splicing model\n",
    "model_name = \"HAL\"\n",
    "# get the model\n",
    "model = kipoi.get_model(model_name)\n",
    "# get the dataloader factory\n",
    "Dataloader = kipoi.get_dataloader_factory(model_name)\n",
    "# The input vcf path\n",
    "vcf_path = \"example_data/clinvar_donor_acceptor_chr22.vcf\"\n",
    "\n",
    "# Make sure that the vcf is bgzipped and tabixed, if not then generate the compressed vcf in the same place\n",
    "vcf_path_tbx = ensure_tabixed_vcf(vcf_path)\n",
    "\n",
    "# The output vcf path, based on the input file name    \n",
    "out_vcf_fpath = vcf_path[:-4] + \"%s.vcf\"%model_name.replace(\"/\", \"_\")\n",
    "# The writer object that will output the annotated VCF\n",
    "writer = VcfWriter(model, vcf_path, out_vcf_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we don't need an object that generates regions, hence we can directly define the dataloader arguments and run the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 709/709 [00:04<00:00, 150.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from kipoi_veff import predict_snvs\n",
    "from kipoi_veff.scores import Diff\n",
    "dataloader_arguments = {\"gtf_file\":\"example_data/Homo_sapiens.GRCh37.75.filtered_chr22.gtf\",\n",
    "                               \"fasta_file\": \"example_data/hg19_chr22.fa\"}\n",
    "\n",
    "effects = predict_snvs(model,\n",
    "                        Dataloader,\n",
    "                        vcf_path_tbx,\n",
    "                        batch_size = 32,\n",
    "                        dataloader_args=dataloader_arguments,\n",
    "                        evaluation_function_kwargs={'diff_types': {'diff': Diff(\"mean\")}},\n",
    "                        sync_pred_writer=writer,\n",
    "                        return_predictions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the VCF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##fileformat=VCFv4.0\n",
      "##INFO=<ID=KV:kipoi:HAL:DIFF,Number=.,Type=String,Description=\"DIFF SNV effect p...\n",
      "##INFO=<ID=KV:kipoi:HAL:rID,Number=.,Type=String,Description=\"Range or region id...\n",
      "##FILTER=<ID=PASS,Description=\"All filters passed\">\n",
      "##contig=<ID=chr1,length=249250621>\n",
      "##contig=<ID=chr2,length=243199373>\n",
      "##contig=<ID=chr3,length=198022430>\n",
      "##contig=<ID=chr4,length=191154276>\n",
      "##contig=<ID=chr5,length=180915260>\n",
      "##contig=<ID=chr6,length=171115067>\n",
      "##contig=<ID=chr7,length=159138663>\n",
      "##contig=<ID=chr8,length=146364022>\n",
      "##contig=<ID=chr9,length=141213431>\n",
      "##contig=<ID=chr10,length=135534747>\n",
      "##contig=<ID=chr11,length=135006516>\n",
      "##contig=<ID=chr12,length=133851895>\n",
      "##contig=<ID=chr13,length=115169878>\n",
      "##contig=<ID=chr14,length=107349540>\n",
      "##contig=<ID=chr15,length=102531392>\n",
      "##contig=<ID=chr16,length=90354753>\n",
      "##contig=<ID=chr17,length=81195210>\n",
      "##contig=<ID=chr18,length=78077248>\n",
      "##contig=<ID=chr19,length=59128983>\n",
      "##contig=<ID=chr20,length=63025520>\n",
      "##contig=<ID=chr21,length=48129895>\n",
      "##contig=<ID=chr22,length=51304566>\n",
      "##contig=<ID=chrX,length=155270560>\n",
      "##contig=<ID=chrY,length=59373566>\n",
      "##contig=<ID=chrMT,length=16569>\n",
      "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\n",
      "chr22\t17684454\t4461\tG\tA\t.\t.\tKV:kipoi:HAL:DIFF=0.10586491;KV:kipoi:HAL:rID=290\n",
      "chr22\t17669232\t7178\tT\tC\t.\t.\tKV:kipoi:HAL:DIFF=0.00000000;KV:kipoi:HAL:rID=293\n",
      "chr22\t17669232\t7178\tT\tC\t.\t.\tKV:kipoi:HAL:DIFF=0.00000000;KV:kipoi:HAL:rID=299\n",
      "chr22\t17684454\t4461\tG\tA\t.\t.\tKV:kipoi:HAL:DIFF=0.10586491;KV:kipoi:HAL:rID=304\n",
      "chr22\t17669232\t7178\tT\tC\t.\t.\tKV:kipoi:HAL:DIFF=0.00000000;KV:kipoi:HAL:rID=307\n",
      "chr22\t17684454\t4461\tG\tA\t.\t.\tKV:kipoi:HAL:DIFF=0.10586491;KV:kipoi:HAL:rID=313\n",
      "chr22\t17669232\t7178\tT\tC\t.\t.\tKV:kipoi:HAL:DIFF=0.00000000;KV:kipoi:HAL:rID=316\n",
      "chr22\t17684454\t4461\tG\tA\t.\t.\tKV:kipoi:HAL:DIFF=0.10586491;KV:kipoi:HAL:rID=322\n",
      "chr22\t17669232\t7178\tT\tC\t.\t.\tKV:kipoi:HAL:DIFF=0.00000000;KV:kipoi:HAL:rID=325\n",
      "chr22\t17669232\t7178\tT\tC\t.\t.\tKV:kipoi:HAL:DIFF=0.00000000;KV:kipoi:HAL:rID=328\n",
      "chr22\t18561370\t7302\tC\tT\t.\t.\tKV:kipoi:HAL:DIFF=-1.33794269;KV:kipoi:HAL:rID=824\n"
     ]
    }
   ],
   "source": [
    "# A slightly convoluted way of printing out the first 40 lines and up to 80 characters per line maximum\n",
    "with open(\"example_data/clinvar_donor_acceptor_chr22HAL.vcf\") as ifh:\n",
    "    for i,l in enumerate(ifh):\n",
    "        long_line = \"\"\n",
    "        if len(l)>80:\n",
    "            long_line = \"...\"\n",
    "        print(l[:80].rstrip() +long_line)\n",
    "        if i >=40:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the prediction output this time is less helpful because it's the ids that the dataloader created which are displayed as index. In general it is advisable to use the output VCF for more detailed information on which variant was overlapped with which region fo produce a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff\n",
      "            0\n",
      "290  0.105865\n",
      "293  0.000000\n",
      "299  0.000000\n",
      "304  0.105865\n",
      "307  0.000000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for k in effects:\n",
    "    print(k)\n",
    "    print(effects[k].head())\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command-line based effect prediction\n",
    "The above command can also conveniently be executed using the command line:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kipoi veff score_variants DeepSEA/variantEffects --dataloader_args='{\"fasta_file\": \"example_data/hg19_chr22.fa\"}' -i example_data/clinvar_donor_acceptor_chr22.vcf -o example_data/clinvar_donor_acceptor_chr22DeepSEA_variantEffects.vcf -s diff deepsea_effect\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "model_name = \"DeepSEA/variantEffects\"\n",
    "dl_args = json.dumps({\"fasta_file\": \"example_data/hg19_chr22.fa\"})\n",
    "out_vcf_fpath = vcf_path[:-4] + \"%s.vcf\"%model_name.replace(\"/\", \"_\")\n",
    "scorings = \"diff deepsea_effect\"\n",
    "command = (\"kipoi veff score_variants {model} \"\n",
    "           \"--dataloader_args='{dl_args}' \"\n",
    "           \"-i {input_vcf} \"\n",
    "           \"-o {output_vcf} \"\n",
    "           \"-s {scorings}\").format(model=model_name,\n",
    "                                          dl_args=dl_args,\n",
    "                                          input_vcf=vcf_path,\n",
    "                                          output_vcf=out_vcf_fpath,\n",
    "                                          scorings=scorings)\n",
    "# Print out the command:\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m Update /nfs/research1/stegle/users/rkreuzhu/.kipoi/models/\u001b[0m\n",
      "Already up-to-date.\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/variantEffects/**\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/template/**\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/template/model_files/**\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/template/example_files/**\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m model DeepSEA/variantEffects loaded\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/variantEffects/./**\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/template/**\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/template/model_files/**\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/template/example_files/**\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m dataloader DeepSEA/variantEffects/. loaded\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi.data]\u001b[0m successfully loaded the dataloader from /nfs/research1/stegle/users/rkreuzhu/.kipoi/models/DeepSEA/variantEffects/dataloader.py::SeqDataset\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi.pipeline]\u001b[0m dataloader.output_schema is compatible with model.schema\u001b[0m\n",
      "100%|███████████████████████████████████████████| 14/14 [00:35<00:00,  2.53s/it]\n"
     ]
    }
   ],
   "source": [
    "! $command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch prediction\n",
    "Since the syntax basically doesn't change for different kinds of models a simple for-loop can be written to do what we just did on many models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/research1/stegle/users/rkreuzhu/opt/model-zoo/kipoi/config.py:110: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat(pd_list)[pd_list[0].columns]\n"
     ]
    }
   ],
   "source": [
    "import kipoi\n",
    "# Run effect predicton\n",
    "models_df = kipoi.list_models()\n",
    "models_substr = [\"HAL\", \"MaxEntScan\", \"labranchor\", \"rbp\"]\n",
    "models_df_subsets = {ms: models_df.loc[models_df[\"model\"].str.contains(ms)] for ms in models_substr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 709/709 [00:04<00:00, 167.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxEntScan/3prime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 709/709 [00:02<00:00, 329.18it/s]\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/models.py:287: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labranchor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 709/709 [00:05<00:00, 122.95it/s]\n",
      "2018-07-25 11:37:28,705 [INFO] successfully loaded the dataloader from /nfs/research1/stegle/users/rkreuzhu/.kipoi/models/rbp_eclip/AARS/dataloader.py::SeqDistDataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-25 11:37:28,851 [WARNING] From /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "/nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/models.py:287: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n",
      "2018-07-25 11:37:30,996 [INFO] successfully loaded the model from model_files/model.h5\n",
      "2018-07-25 11:37:30,999 [INFO] dataloader.output_schema is compatible with model.schema\n",
      "2018-07-25 11:37:31,157 [INFO] git-lfs pull -I rbp_eclip/AARS/**\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbp_eclip/AARS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-25 11:37:32,071 [INFO] git-lfs pull -I rbp_eclip/template/**\n",
      "2018-07-25 11:37:33,219 [INFO] dataloader rbp_eclip/AARS loaded\n",
      "2018-07-25 11:37:33,252 [INFO] successfully loaded the dataloader from /nfs/research1/stegle/users/rkreuzhu/.kipoi/models/rbp_eclip/AARS/dataloader.py::SeqDistDataset\n",
      "2018-07-25 11:37:34,411 [INFO] Extracted GTF attributes: ['gene_id', 'gene_name', 'gene_source', 'gene_biotype', 'transcript_id', 'transcript_name', 'transcript_source', 'exon_number', 'exon_id', 'tag', 'protein_id', 'ccds_id']\n",
      "/nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.18.1 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator Imputer from version 0.18.1 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]INFO:2018-07-25 11:37:34,812:genomelake] Running landmark extractors..\n",
      "2018-07-25 11:37:34,812 [INFO] Running landmark extractors..\n",
      "/nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/concise/utils/position.py:55: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "  (\"strand\", gtf.strand)])\n",
      "/nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/concise/utils/position.py:62: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "  (\"strand\", gtf.strand)])\n",
      "INFO:2018-07-25 11:37:34,975:genomelake] Done!\n",
      "2018-07-25 11:37:34,975 [INFO] Done!\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run variant effect prediction using a basic Diff\n",
    "\n",
    "import kipoi\n",
    "from kipoi_veff import ensure_tabixed_vcf\n",
    "import kipoi_veff.snv_predict as sp\n",
    "from kipoi_veff import VcfWriter\n",
    "from kipoi_veff.scores import Diff\n",
    "\n",
    "\n",
    "\n",
    "splicing_dl_args = {\"gtf_file\":\"example_data/Homo_sapiens.GRCh37.75.filtered_chr22.gtf\",\n",
    "                               \"fasta_file\": \"example_data/hg19_chr22.fa\"}\n",
    "dataloader_args_dict = {\"HAL\": splicing_dl_args,\n",
    "                        \"labranchor\": splicing_dl_args,\n",
    "                        \"MaxEntScan\":splicing_dl_args,\n",
    "                        \"rbp\": {\"fasta_file\": \"example_data/hg19_chr22.fa\",\n",
    "                               \"gtf_file\":\"example_data/Homo_sapiens.GRCh37.75_chr22.gtf\"}\n",
    "                       }\n",
    "\n",
    "for ms in models_substr:\n",
    "    model_name = models_df_subsets[ms][\"model\"].iloc[0]\n",
    "    #kipoi.pipeline.install_model_requirements(model_name)\n",
    "    model = kipoi.get_model(model_name)\n",
    "    vcf_path = \"example_data/clinvar_donor_acceptor_chr22.vcf\"\n",
    "    vcf_path_tbx = ensure_tabixed_vcf(vcf_path)\n",
    "    \n",
    "    out_vcf_fpath = vcf_path[:-4] + \"%s.vcf\"%model_name.replace(\"/\", \"_\")\n",
    "\n",
    "    writer = VcfWriter(model, vcf_path, out_vcf_fpath)\n",
    "    \n",
    "    print(model_name)\n",
    "    \n",
    "    Dataloader = kipoi.get_dataloader_factory(model_name)\n",
    "    dataloader_arguments = dataloader_args_dict[ms]\n",
    "    model_info = kipoi_veff.ModelInfoExtractor(model, Dataloader)\n",
    "    vcf_to_region = None\n",
    "    if ms == \"rbp\":\n",
    "        vcf_to_region = kipoi_veff.SnvCenteredRg(model_info)\n",
    "    sp.predict_snvs(model,\n",
    "                    Dataloader,\n",
    "                    vcf_path_tbx,\n",
    "                    batch_size = 32,\n",
    "                    dataloader_args=dataloader_arguments,\n",
    "                    vcf_to_region=vcf_to_region,\n",
    "                    evaluation_function_kwargs={'diff_types': {'diff': Diff(\"mean\")}},\n",
    "                    sync_pred_writer=writer)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's validate that things have worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    450 example_data/clinvar_donor_acceptor_chr22DeepSEA_variantEffects.vcf\n",
      "   2035 example_data/clinvar_donor_acceptor_chr22HAL.vcf\n",
      "    794 example_data/clinvar_donor_acceptor_chr22labranchor.vcf\n",
      "   1176 example_data/clinvar_donor_acceptor_chr22MaxEntScan_3prime.vcf\n",
      "    449 example_data/clinvar_donor_acceptor_chr22rbp_eclip_AARS.vcf\n",
      "    447 example_data/clinvar_donor_acceptor_chr22.vcf\n",
      "   5351 total\n"
     ]
    }
   ],
   "source": [
    "! wc -l example_data/clinvar_donor_acceptor_chr22*.vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
